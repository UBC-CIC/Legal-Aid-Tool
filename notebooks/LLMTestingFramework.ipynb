{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cddb7d8-250c-49b4-a95b-558216277012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lm-format-enforcer\n",
      "  Downloading lm_format_enforcer-0.10.10-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting interegular>=0.3.2 (from lm-format-enforcer)\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lm-format-enforcer) (24.2)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lm-format-enforcer) (2.10.6)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lm-format-enforcer) (6.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=1.10.8->lm-format-enforcer) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=1.10.8->lm-format-enforcer) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=1.10.8->lm-format-enforcer) (4.12.2)\n",
      "Downloading lm_format_enforcer-0.10.10-py3-none-any.whl (44 kB)\n",
      "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Installing collected packages: interegular, lm-format-enforcer\n",
      "Successfully installed interegular-0.3.3 lm-format-enforcer-0.10.10\n"
     ]
    }
   ],
   "source": [
    "!pip install lm-format-enforcer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b2d331-11f7-4e3b-ae61-01b8a38195db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import transformers\n",
    "from pydantic import BaseModel\n",
    "from lmformatenforcer import JsonSchemaParser\n",
    "from lmformatenforcer.integrations.transformers import (\n",
    "    build_transformers_prefix_allowed_tokens_fn,\n",
    ")\n",
    "\n",
    "from deepeval.models import DeepEvalBaseLLM\n",
    "\n",
    "\n",
    "class CustomLLM(DeepEvalBaseLLM):\n",
    "    ...\n",
    "\n",
    "    def generate(self, prompt: str, schema: BaseModel) -> BaseModel:\n",
    "        # Same as the previous example above\n",
    "        model = self.load_model()\n",
    "        pipeline = transformers.pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            use_cache=True,\n",
    "            device_map=\"auto\",\n",
    "            max_length=2500,\n",
    "            do_sample=True,\n",
    "            top_k=5,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=self.tokenizer.eos_token_id,\n",
    "            pad_token_id=self.tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "        # Create parser required for JSON confinement using lmformatenforcer\n",
    "        parser = JsonSchemaParser(schema.model_json_schema())\n",
    "        prefix_function = build_transformers_prefix_allowed_tokens_fn(\n",
    "            pipeline.tokenizer, parser\n",
    "        )\n",
    "\n",
    "        # Output and load valid JSON\n",
    "        output_dict = pipeline(prompt, prefix_allowed_tokens_fn=prefix_function)\n",
    "        output = output_dict[0][\"generated_text\"][len(prompt) :]\n",
    "        json_result = json.loads(output)\n",
    "\n",
    "        # Return valid JSON object according to the schema DeepEval supplied\n",
    "        return schema(**json_result)\n",
    "\n",
    "    async def a_generate(self, prompt: str, schema: BaseModel) -> BaseModel:\n",
    "        return self.generate(prompt, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acf265f-b7c1-4480-9365-4c62135f8bcb",
   "metadata": {},
   "source": [
    "# Docs\n",
    "\n",
    "[Creating a custom LLM](https://github.com/confident-ai/deepeval/blob/main/docs/guides/guides-using-custom-llms.mdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4497dd0d-1331-4843-bed3-c7c1d854690a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
