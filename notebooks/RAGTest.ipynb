{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bdc4fc6-c840-4093-b185-0644bab5fc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sphinx 8.1.3 requires docutils<0.22,>=0.20, but you have docutils 0.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "Imported and installed dependencies!\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet -U langchain langchain-community langchain-aws langchain-core pgvector\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import psycopg2\n",
    "import ast\n",
    "import pgvector\n",
    "import math\n",
    "from psycopg2.extras import execute_values\n",
    "from pgvector.psycopg2 import register_vector\n",
    "import boto3\n",
    "from langchain_community.embeddings.bedrock import BedrockEmbeddings\n",
    "from langchain_aws import BedrockLLM\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "print(\"Imported and installed dependencies!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f0fab84-63f8-439f-893e-514e9bb3f699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.05515049770474434,\n",
       " 0.04516850784420967,\n",
       " 0.02720092423260212,\n",
       " 0.006394712720066309,\n",
       " 0.04142526164650917,\n",
       " -0.0359351672232151,\n",
       " 0.009233341552317142,\n",
       " 0.0314432717859745,\n",
       " 0.017094159498810768,\n",
       " 0.010793027468025684,\n",
       " -0.009794828481972218,\n",
       " 0.03718291595578194,\n",
       " 0.007611267734318972,\n",
       " -0.05415229871869087,\n",
       " -0.011104964651167393,\n",
       " -0.03543606773018837,\n",
       " -0.014972985722124577,\n",
       " -0.035685617476701736,\n",
       " 0.04766400530934334,\n",
       " 0.002916612895205617,\n",
       " -0.03393876925110817,\n",
       " 0.016220735386013985,\n",
       " 0.03393876925110817,\n",
       " -0.020587855949997902,\n",
       " -0.027700023725628853,\n",
       " -0.02607795037329197,\n",
       " -0.035186517983675,\n",
       " -0.03543606773018837,\n",
       " 0.00948289129883051,\n",
       " -0.05714689567685127,\n",
       " 0.04741445556282997,\n",
       " -0.0070497808046638966,\n",
       " -0.008235142566263676,\n",
       " -0.01397478673607111,\n",
       " 0.0160959605127573,\n",
       " 0.03793156519532204,\n",
       " 0.019963981583714485,\n",
       " -0.02345767803490162,\n",
       " -0.012352713383734226,\n",
       " -0.01647028513252735,\n",
       " 0.05440184846520424,\n",
       " -0.028199123218655586,\n",
       " -0.0061139692552387714,\n",
       " 0.021086955443024635,\n",
       " 0.002885419176891446,\n",
       " 0.035685617476701736,\n",
       " 0.022209929302334785,\n",
       " 0.031942371279001236,\n",
       " 0.042673010379076004,\n",
       " -0.008734242059290409,\n",
       " -0.011666451580822468,\n",
       " 0.024331102147698402,\n",
       " -0.04516850784420967,\n",
       " 0.02794957347214222,\n",
       " -0.007018587086349726,\n",
       " 0.013163750059902668,\n",
       " -0.003322131233289838,\n",
       " 0.047913555055856705,\n",
       " -0.008921404369175434,\n",
       " 0.01509776059538126,\n",
       " 0.01934010721743107,\n",
       " -0.008609467186033726,\n",
       " 0.03843066468834877,\n",
       " 0.001442709588445723,\n",
       " 0.0007720445864833891,\n",
       " -0.039678413420915604,\n",
       " -0.0329405702650547,\n",
       " 0.00567725719884038,\n",
       " -0.001388120581395924,\n",
       " 0.00530293257907033,\n",
       " -0.01821713335812092,\n",
       " 0.009794828481972218,\n",
       " -0.0038368275854736567,\n",
       " -0.049410853534936905,\n",
       " -0.0168446097522974,\n",
       " 0.008484692312777042,\n",
       " 0.043421659618616104,\n",
       " -0.008859016932547092,\n",
       " -0.06263699382543564,\n",
       " 0.07785952836275101,\n",
       " 0.01647028513252735,\n",
       " 0.00530293257907033,\n",
       " -0.044918958097696304,\n",
       " -0.010793027468025684,\n",
       " 0.04292256012558937,\n",
       " -0.002807434881106019,\n",
       " 0.02008875645697117,\n",
       " 0.04516850784420967,\n",
       " -0.007892011664807796,\n",
       " -0.021336505189538002,\n",
       " -0.016220735386013985,\n",
       " 0.003852424444630742,\n",
       " 0.02420632727444172,\n",
       " 0.02383200265467167,\n",
       " 0.04017751291394234,\n",
       " 0.003665262134745717,\n",
       " -0.005739644635468721,\n",
       " -0.04666580632328987,\n",
       " -0.038929764181375504,\n",
       " -0.04466940835118294,\n",
       " -0.014161949045956135,\n",
       " 0.02869822271168232,\n",
       " 0.032691020518541336,\n",
       " -0.012227938510477543,\n",
       " 0.03643426671624184,\n",
       " 0.021461280062794685,\n",
       " -0.0190905574709177,\n",
       " 0.012352713383734226,\n",
       " 0.02196037955582142,\n",
       " 0.007985592819750309,\n",
       " 0.004710251931101084,\n",
       " 0.017468484118580818,\n",
       " 0.017094159498810768,\n",
       " -0.03793156519532204,\n",
       " -0.003446906106546521,\n",
       " -0.04616670683026314,\n",
       " -0.006363519001752138,\n",
       " 0.035685617476701736,\n",
       " 0.04666580632328987,\n",
       " 0.02345767803490162,\n",
       " -0.009981990791857243,\n",
       " 0.026951374486088753,\n",
       " 0.0012165551306679845,\n",
       " 0.027450473979115486,\n",
       " -0.013538074679672718,\n",
       " -0.027325699105858803,\n",
       " -0.03718291595578194,\n",
       " -0.04142526164650917,\n",
       " -0.00246430397965014,\n",
       " 0.03094417043030262,\n",
       " 0.05440184846520424,\n",
       " -0.04816310480237007,\n",
       " -0.025454076007008553,\n",
       " -0.007985592819750309,\n",
       " 0.019464882090687752,\n",
       " 0.044170308858156204,\n",
       " -0.07386673241853714,\n",
       " -0.010481090284883976,\n",
       " -0.0718703344464302,\n",
       " 0.028074348345398903,\n",
       " -0.015971185639500618,\n",
       " 0.03768201544880867,\n",
       " -0.002058785641565919,\n",
       " -0.031942371279001236,\n",
       " 0.08634421974420547,\n",
       " -0.03094417043030262,\n",
       " 0.009233341552317142,\n",
       " -0.003774440148845315,\n",
       " 0.00985721591860056,\n",
       " 0.0026670631486922503,\n",
       " -0.05739644542336464,\n",
       " 0.020213531330227852,\n",
       " 0.013101362623274326,\n",
       " 0.05215590074658394,\n",
       " 0.02720092423260212,\n",
       " 0.024331102147698402,\n",
       " -0.002433110261335969,\n",
       " 0.01397478673607111,\n",
       " -0.0336892195045948,\n",
       " 0.0718703344464302,\n",
       " 0.0014115158701315522,\n",
       " 0.00015011978393886238,\n",
       " 0.08035502582788467,\n",
       " -0.041924361139535904,\n",
       " 0.05415229871869087,\n",
       " -0.018466683104634285,\n",
       " -0.026701824739575386,\n",
       " -0.011604064144194126,\n",
       " -0.017343709245324135,\n",
       " -0.01172883901745081,\n",
       " 0.04142526164650917,\n",
       " -0.03992796316742897,\n",
       " -0.01896578259766102,\n",
       " 0.01934010721743107,\n",
       " -0.04392075911164284,\n",
       " 0.042673010379076004,\n",
       " 0.0016142750391736627,\n",
       " -0.01565924845635891,\n",
       " -0.0748649314045906,\n",
       " 0.029945971444249153,\n",
       " 0.01871623285114765,\n",
       " -0.005209351424127817,\n",
       " -0.016719834879040718,\n",
       " -0.04516850784420967,\n",
       " 0.04616670683026314,\n",
       " -0.03843066468834877,\n",
       " 0.019464882090687752,\n",
       " -0.03181759640574455,\n",
       " -0.015222535468637943,\n",
       " -0.023208128288388252,\n",
       " -0.02046308107674122,\n",
       " 0.010793027468025684,\n",
       " -6.238744390429929e-05,\n",
       " -0.05664779618382454,\n",
       " 0.007954399101436138,\n",
       " 0.039678413420915604,\n",
       " -0.0028542254585772753,\n",
       " -0.029322097077965736,\n",
       " 0.08235142379999161,\n",
       " 0.038929764181375504,\n",
       " 0.005864419508725405,\n",
       " -0.03942886367440224,\n",
       " 0.031193720176815987,\n",
       " -0.009732441045343876,\n",
       " -0.024705426767468452,\n",
       " 0.031068945303559303,\n",
       " 0.042673010379076004,\n",
       " 0.020587855949997902,\n",
       " -0.010543477721512318,\n",
       " -0.011604064144194126,\n",
       " -0.03244147077202797,\n",
       " -0.01547208521515131,\n",
       " -0.031942371279001236,\n",
       " -0.029197322204709053,\n",
       " -0.03543606773018837,\n",
       " -0.00910856667906046,\n",
       " 0.059891942888498306,\n",
       " -0.011104964651167393,\n",
       " -0.0329405702650547,\n",
       " 0.019464882090687752,\n",
       " 0.02158605493605137,\n",
       " 0.008297530002892017,\n",
       " -0.01434911135584116,\n",
       " 0.03094417043030262,\n",
       " 0.025454076007008553,\n",
       " -0.00910856667906046,\n",
       " -0.001629871898330748,\n",
       " -0.044170308858156204,\n",
       " 0.048662204295396805,\n",
       " 0.012976587750017643,\n",
       " -0.06313609331846237,\n",
       " -0.026701824739575386,\n",
       " -0.0314432717859745,\n",
       " -0.011541676707565784,\n",
       " -0.017468484118580818,\n",
       " 0.023208128288388252,\n",
       " -0.028947772458195686,\n",
       " -0.0190905574709177,\n",
       " 0.0049598016776144505,\n",
       " -0.005209351424127817,\n",
       " -0.012602263130247593,\n",
       " -0.047164905816316605,\n",
       " -0.033439669758081436,\n",
       " 0.038929764181375504,\n",
       " 0.026202725246548653,\n",
       " 0.007517686579376459,\n",
       " -0.00246430397965014,\n",
       " 0.028947772458195686,\n",
       " -0.04067661240696907,\n",
       " -0.2794957458972931,\n",
       " 0.017094159498810768,\n",
       " 0.031193720176815987,\n",
       " 0.04666580632328987,\n",
       " 0.038929764181375504,\n",
       " 0.002651466289535165,\n",
       " 0.003961602691560984,\n",
       " -0.007424105424433947,\n",
       " 0.019589656963944435,\n",
       " -0.023208128288388252,\n",
       " -0.0381811149418354,\n",
       " -0.007860817946493626,\n",
       " 0.006925005931407213,\n",
       " 0.001255547278560698,\n",
       " -0.02420632727444172,\n",
       " -0.0175932589918375,\n",
       " -0.01247748825699091,\n",
       " 0.007517686579376459,\n",
       " -0.027325699105858803,\n",
       " 0.015409697778522968,\n",
       " 0.0039927964098751545,\n",
       " 0.007767236325889826,\n",
       " 0.022085154429078102,\n",
       " 0.012040776200592518,\n",
       " -0.015160148032009602,\n",
       " -0.005209351424127817,\n",
       " -0.06089014187455177,\n",
       " 0.0168446097522974,\n",
       " -0.04966040328145027,\n",
       " -0.004398314747959375,\n",
       " 0.039678413420915604,\n",
       " 0.004990995395928621,\n",
       " -0.031942371279001236,\n",
       " -0.016345510259270668,\n",
       " -0.009919603355228901,\n",
       " -0.014972985722124577,\n",
       " -0.022209929302334785,\n",
       " -0.02008875645697117,\n",
       " 0.023208128288388252,\n",
       " 0.023707227781414986,\n",
       " 0.015908798202872276,\n",
       " 0.013163750059902668,\n",
       " -0.01896578259766102,\n",
       " 0.007361717987805605,\n",
       " -0.053902748972177505,\n",
       " -0.011479289270937443,\n",
       " 0.0688757374882698,\n",
       " -0.01971443183720112,\n",
       " 0.02645227499306202,\n",
       " 0.01285181287676096,\n",
       " -0.04292256012558937,\n",
       " 0.02008875645697117,\n",
       " 0.019215332344174385,\n",
       " 0.0023083353880792856,\n",
       " -0.04167481139302254,\n",
       " 0.047164905816316605,\n",
       " -0.028199123218655586,\n",
       " -0.0190905574709177,\n",
       " -0.053154099732637405,\n",
       " 0.02458065189421177,\n",
       " 0.06113969162106514,\n",
       " -0.01285181287676096,\n",
       " 0.001255547278560698,\n",
       " 0.015409697778522968,\n",
       " 0.011104964651167393,\n",
       " 0.011978388763964176,\n",
       " 0.035685617476701736,\n",
       " 0.013163750059902668,\n",
       " 0.03543606773018837,\n",
       " -0.01859145797789097,\n",
       " -0.02570362575352192,\n",
       " -0.054651398211717606,\n",
       " 0.005583676043897867,\n",
       " -0.0008812226005829871,\n",
       " -0.053902748972177505,\n",
       " -0.0005302932695485651,\n",
       " 0.04017751291394234,\n",
       " -0.002885419176891446,\n",
       " 0.016969384625554085,\n",
       " -0.004772639367729425,\n",
       " -0.0027918380219489336,\n",
       " -0.0010527881095185876,\n",
       " -0.06687933951616287,\n",
       " -0.010418702848255634,\n",
       " -0.03768201544880867,\n",
       " -0.0359351672232151,\n",
       " 0.018841007724404335,\n",
       " 0.028822997584939003,\n",
       " 0.014224336482584476,\n",
       " -0.054651398211717606,\n",
       " -0.017842808738350868,\n",
       " 0.011042577214539051,\n",
       " 0.007798430044203997,\n",
       " -0.014286723919212818,\n",
       " -0.045667607337236404,\n",
       " 0.013101362623274326,\n",
       " -0.006020388100296259,\n",
       " -0.022209929302334785,\n",
       " 0.01098018977791071,\n",
       " -0.00985721591860056,\n",
       " -0.006987393368035555,\n",
       " -0.003930408973246813,\n",
       " 0.0010449896799400449,\n",
       " 0.022085154429078102,\n",
       " -0.02907254733145237,\n",
       " -0.05065860226750374,\n",
       " 0.026701824739575386,\n",
       " 0.011853613890707493,\n",
       " 0.004866220522671938,\n",
       " 0.0043671210296452045,\n",
       " 0.009358116425573826,\n",
       " -0.044918958097696304,\n",
       " -0.04217391088604927,\n",
       " -0.019215332344174385,\n",
       " -0.0022615448106080294,\n",
       " 0.010106765665113926,\n",
       " 0.039678413420915604,\n",
       " -0.007673655170947313,\n",
       " 0.02907254733145237,\n",
       " -0.016719834879040718,\n",
       " 0.019589656963944435,\n",
       " -0.054651398211717606,\n",
       " 0.002776241162791848,\n",
       " 0.050908152014017105,\n",
       " -0.0006706650019623339,\n",
       " 0.004990995395928621,\n",
       " 0.007112168241292238,\n",
       " 0.044170308858156204,\n",
       " -0.03543606773018837,\n",
       " -0.0031973563600331545,\n",
       " 0.07286853343248367,\n",
       " 0.02532930113375187,\n",
       " 0.02944687195122242,\n",
       " -0.02869822271168232,\n",
       " -0.0175932589918375,\n",
       " 0.00910856667906046,\n",
       " -0.014161949045956135,\n",
       " -0.006176356691867113,\n",
       " -0.024705426767468452,\n",
       " -0.004117571283131838,\n",
       " -0.05664779618382454,\n",
       " 0.002136769937351346,\n",
       " -0.02570362575352192,\n",
       " 0.01285181287676096,\n",
       " 0.02757524885237217,\n",
       " 0.027700023725628853,\n",
       " 0.005833225790411234,\n",
       " -0.002651466289535165,\n",
       " 0.014473886229097843,\n",
       " 0.031068945303559303,\n",
       " 0.0045854770578444,\n",
       " -0.018841007724404335,\n",
       " 0.05140725150704384,\n",
       " -0.0019340106518939137,\n",
       " -0.004460702184587717,\n",
       " 0.03169282153248787,\n",
       " 0.03019552119076252,\n",
       " 0.023956777527928352,\n",
       " 0.025204526260495186,\n",
       " -0.02532930113375187,\n",
       " -0.0329405702650547,\n",
       " 0.03244147077202797,\n",
       " -0.01172883901745081,\n",
       " 0.002245947951450944,\n",
       " 0.0321919210255146,\n",
       " -0.019464882090687752,\n",
       " -0.0053341262973845005,\n",
       " 0.04092616215348244,\n",
       " 0.002916612895205617,\n",
       " -0.04217391088604927,\n",
       " -0.03643426671624184,\n",
       " -0.02383200265467167,\n",
       " 0.028448672965168953,\n",
       " 0.013725236989557743,\n",
       " -0.03643426671624184,\n",
       " -0.020338306203484535,\n",
       " 0.03618471696972847,\n",
       " 0.029322097077965736,\n",
       " -0.022459479048848152,\n",
       " 0.04691535606980324,\n",
       " 0.007580074016004801,\n",
       " -0.04691535606980324,\n",
       " 0.021461280062794685,\n",
       " -0.028074348345398903,\n",
       " -0.034936968237161636,\n",
       " 0.00010137959179701284,\n",
       " 0.010418702848255634,\n",
       " 0.014972985722124577,\n",
       " 0.0008656257414259017,\n",
       " 0.023707227781414986,\n",
       " -0.021461280062794685,\n",
       " 0.019215332344174385,\n",
       " 0.018466683104634285,\n",
       " -0.013725236989557743,\n",
       " -0.014785823412239552,\n",
       " 0.022085154429078102,\n",
       " -0.027824798598885536,\n",
       " -0.010169153101742268,\n",
       " -0.028947772458195686,\n",
       " -0.044170308858156204,\n",
       " -0.006831424776464701,\n",
       " 0.016719834879040718,\n",
       " 0.02233470417559147,\n",
       " 0.0028542254585772753,\n",
       " 0.029945971444249153,\n",
       " -0.027450473979115486,\n",
       " -0.04167481139302254,\n",
       " 0.013038975186645985,\n",
       " -0.010668252594769001,\n",
       " 0.008921404369175434,\n",
       " 0.02869822271168232,\n",
       " -0.04441985860466957,\n",
       " 0.010855414904654026,\n",
       " -0.02944687195122242,\n",
       " 0.029571646824479103,\n",
       " -0.011853613890707493,\n",
       " -0.004741445649415255,\n",
       " 0.004647864494472742,\n",
       " 0.02794957347214222,\n",
       " 0.02046308107674122,\n",
       " -0.010044378228485584,\n",
       " -0.0009046178893186152,\n",
       " 0.022584253922104836,\n",
       " -0.03131849691271782,\n",
       " -0.01859145797789097,\n",
       " 0.0007174555794335902,\n",
       " -0.010293927974998951,\n",
       " -0.04766400530934334,\n",
       " -0.0003509293601382524,\n",
       " -0.04666580632328987,\n",
       " 0.03868021443486214,\n",
       " -0.02158605493605137,\n",
       " 0.011104964651167393,\n",
       " 0.00642590643838048,\n",
       " -0.08035502582788467,\n",
       " 0.010543477721512318,\n",
       " 0.008359917439520359,\n",
       " -0.017343709245324135,\n",
       " -0.04367120936512947,\n",
       " 0.020962180569767952,\n",
       " -0.017718033865094185,\n",
       " 0.000814935949165374,\n",
       " 0.031568046659231186,\n",
       " -0.01472343597561121,\n",
       " 0.03393876925110817,\n",
       " 0.01871623285114765,\n",
       " 0.008983791805803776,\n",
       " -0.0012633457081392407,\n",
       " -0.0160959605127573,\n",
       " -0.01360046211630106,\n",
       " -0.01871623285114765,\n",
       " 0.026577049866318703,\n",
       " 0.001848227926529944,\n",
       " -0.003446906106546521,\n",
       " 0.030694620683789253,\n",
       " 0.044170308858156204,\n",
       " -0.050908152014017105,\n",
       " 0.019839206710457802,\n",
       " 0.026577049866318703,\n",
       " 0.023956777527928352,\n",
       " -0.017343709245324135,\n",
       " -0.017718033865094185,\n",
       " 0.010543477721512318,\n",
       " -0.006363519001752138,\n",
       " -0.016220735386013985,\n",
       " 0.016220735386013985,\n",
       " -0.022833803668618202,\n",
       " 0.022209929302334785,\n",
       " 0.02121173031628132,\n",
       " 0.014224336482584476,\n",
       " -0.0030413877684623003,\n",
       " 0.012415100820362568,\n",
       " 0.0019963982049375772,\n",
       " 0.027325699105858803,\n",
       " -0.03181759640574455,\n",
       " 0.006082775536924601,\n",
       " 0.0074552991427481174,\n",
       " -0.08434782177209854,\n",
       " -0.02794957347214222,\n",
       " -0.01322613749653101,\n",
       " 0.041175711899995804,\n",
       " -0.008983791805803776,\n",
       " -0.011042577214539051,\n",
       " -0.01896578259766102,\n",
       " -0.008235142566263676,\n",
       " 0.040427062660455704,\n",
       " 0.02944687195122242,\n",
       " -0.033439669758081436,\n",
       " 0.01397478673607111,\n",
       " 0.016220735386013985,\n",
       " -0.07037303596735,\n",
       " 0.002994597190991044,\n",
       " 0.07286853343248367,\n",
       " -0.028199123218655586,\n",
       " 0.17169024050235748,\n",
       " -0.024705426767468452,\n",
       " 0.0037900370080024004,\n",
       " -0.0321919210255146,\n",
       " -0.003961602691560984,\n",
       " -0.04541805759072304,\n",
       " 0.01360046211630106,\n",
       " -0.02832389809191227,\n",
       " 0.025204526260495186,\n",
       " 0.016595060005784035,\n",
       " -0.03543606773018837,\n",
       " -0.0183419082313776,\n",
       " -0.0070497808046638966,\n",
       " 0.019589656963944435,\n",
       " -0.012789425440132618,\n",
       " 0.01135451439768076,\n",
       " -0.018092358484864235,\n",
       " 0.04092616215348244,\n",
       " 0.05290454998612404,\n",
       " -0.010855414904654026,\n",
       " 0.002963403472676873,\n",
       " -0.0027138537261635065,\n",
       " 0.016220735386013985,\n",
       " -0.034188318997621536,\n",
       " 0.008609467186033726,\n",
       " -0.0374324657022953,\n",
       " 0.01971443183720112,\n",
       " -0.0010917802574113011,\n",
       " 0.04242346063256264,\n",
       " 0.0007876414456404746,\n",
       " -0.033439669758081436,\n",
       " 0.01210316363722086,\n",
       " 0.0381811149418354,\n",
       " -0.008235142566263676,\n",
       " -0.02008875645697117,\n",
       " -0.007985592819750309,\n",
       " 0.005739644635468721,\n",
       " -0.0011151755461469293,\n",
       " 0.014785823412239552,\n",
       " -0.01896578259766102,\n",
       " 0.021710829809308052,\n",
       " 0.011104964651167393,\n",
       " 0.013288524933159351,\n",
       " -0.023332903161644936,\n",
       " 0.02046308107674122,\n",
       " -0.007860817946493626,\n",
       " 0.004273539874702692,\n",
       " 0.07137123495340347,\n",
       " 0.02794957347214222,\n",
       " -0.0190905574709177,\n",
       " -0.016345510259270668,\n",
       " -0.009046179242432117,\n",
       " 0.010293927974998951,\n",
       " -0.05340364947915077,\n",
       " -0.005739644635468721,\n",
       " 0.0033533249516040087,\n",
       " 0.003025790909305215,\n",
       " 0.054651398211717606,\n",
       " 0.034188318997621536,\n",
       " -0.022833803668618202,\n",
       " -0.013912399299442768,\n",
       " -0.012602263130247593,\n",
       " -0.02420632727444172,\n",
       " -0.012976587750017643,\n",
       " 0.005989194381982088,\n",
       " 0.043421659618616104,\n",
       " 0.01971443183720112,\n",
       " 0.047164905816316605,\n",
       " -0.020587855949997902,\n",
       " -0.0030881783459335566,\n",
       " -0.006550681311637163,\n",
       " 0.039678413420915604,\n",
       " 0.04142526164650917,\n",
       " 0.018466683104634285,\n",
       " -0.0366838164627552,\n",
       " 0.02083740569651127,\n",
       " -0.01859145797789097,\n",
       " -0.028074348345398903,\n",
       " -0.00910856667906046,\n",
       " -0.03169282153248787,\n",
       " -0.0008266335935331881,\n",
       " 0.009732441045343876,\n",
       " -0.01098018977791071,\n",
       " -0.02682659961283207,\n",
       " 0.04741445556282997,\n",
       " 0.004803833086043596,\n",
       " 0.04017751291394234,\n",
       " 0.0009592068963684142,\n",
       " 0.006737843621522188,\n",
       " 0.007736042607575655,\n",
       " 0.01721893437206745,\n",
       " 0.030445070937275887,\n",
       " -0.015035373158752918,\n",
       " -0.013350912369787693,\n",
       " -0.005989194381982088,\n",
       " -0.008547079749405384,\n",
       " 0.02083740569651127,\n",
       " 0.055400047451257706,\n",
       " 0.01360046211630106,\n",
       " 0.009295728988945484,\n",
       " -0.054651398211717606,\n",
       " 0.0061139692552387714,\n",
       " -0.01247748825699091,\n",
       " 0.03793156519532204,\n",
       " 0.0012477488489821553,\n",
       " 0.028573447838425636,\n",
       " -0.002651466289535165,\n",
       " -0.0359351672232151,\n",
       " -0.004741445649415255,\n",
       " -0.02982119657099247,\n",
       " -0.06238744035363197,\n",
       " -0.029197322204709053,\n",
       " -0.018466683104634285,\n",
       " -0.014661048538982868,\n",
       " 0.017343709245324135,\n",
       " -0.024705426767468452,\n",
       " 0.030694620683789253,\n",
       " 0.009732441045343876,\n",
       " 0.01060586515814066,\n",
       " -0.029322097077965736,\n",
       " 0.00321295321919024,\n",
       " 0.0183419082313776,\n",
       " -0.004647864494472742,\n",
       " 0.005271738860756159,\n",
       " -0.016345510259270668,\n",
       " -0.0329405702650547,\n",
       " -0.00421115243807435,\n",
       " -0.006238744128495455,\n",
       " 0.03543606773018837,\n",
       " -0.04766400530934334,\n",
       " 0.03468741849064827,\n",
       " -0.011541676707565784,\n",
       " 0.026327500119805336,\n",
       " -0.03056984581053257,\n",
       " 0.004679058212786913,\n",
       " 0.0039927964098751545,\n",
       " 0.01060586515814066,\n",
       " 0.05340364947915077,\n",
       " -0.011666451580822468,\n",
       " -0.007112168241292238,\n",
       " 0.007392911706119776,\n",
       " 0.015784023329615593,\n",
       " 0.005053382832556963,\n",
       " 0.013850011862814426,\n",
       " 0.029322097077965736,\n",
       " 0.0009280131780542433,\n",
       " -0.026577049866318703,\n",
       " -0.03643426671624184,\n",
       " 0.0032753406558185816,\n",
       " -0.017468484118580818,\n",
       " -0.001177562982775271,\n",
       " 0.014785823412239552,\n",
       " -0.006550681311637163,\n",
       " 0.007985592819750309,\n",
       " -0.02682659961283207,\n",
       " 0.019963981583714485,\n",
       " 0.029696421697735786,\n",
       " -0.025828400626778603,\n",
       " 0.015160148032009602,\n",
       " 0.013912399299442768,\n",
       " 0.020213531330227852,\n",
       " 0.0024175134021788836,\n",
       " 0.029197322204709053,\n",
       " -0.024081552401185036,\n",
       " -0.04466940835118294,\n",
       " 0.021461280062794685,\n",
       " 0.01721893437206745,\n",
       " -0.025828400626778603,\n",
       " 0.001310136285610497,\n",
       " -0.035685617476701736,\n",
       " 0.025079751387238503,\n",
       " 0.04392075911164284,\n",
       " 0.015908798202872276,\n",
       " 0.0336892195045948,\n",
       " 0.011229739524424076,\n",
       " 0.04990995302796364,\n",
       " -0.0366838164627552,\n",
       " -0.02458065189421177,\n",
       " -0.03019552119076252,\n",
       " 0.014598661102354527,\n",
       " 0.030819395557045937,\n",
       " -0.04516850784420967,\n",
       " 0.02869822271168232,\n",
       " -0.0168446097522974,\n",
       " 0.04990995302796364,\n",
       " 0.0034313092473894358,\n",
       " -0.027076149359345436,\n",
       " -0.030320296064019203,\n",
       " -0.008859016932547092,\n",
       " 0.00879662949591875,\n",
       " -0.04242346063256264,\n",
       " 0.05939284339547157,\n",
       " -0.04441985860466957,\n",
       " -0.01796758361160755,\n",
       " -0.05515049770474434,\n",
       " 0.02420632727444172,\n",
       " 0.044170308858156204,\n",
       " -0.0329405702650547,\n",
       " 0.02270902879536152,\n",
       " 0.02196037955582142,\n",
       " 0.02794957347214222,\n",
       " -0.014099561609327793,\n",
       " 0.028448672965168953,\n",
       " 0.002963403472676873,\n",
       " 0.015035373158752918,\n",
       " 0.03056984581053257,\n",
       " -0.004491895902901888,\n",
       " 0.008547079749405384,\n",
       " -0.005178157705813646,\n",
       " 0.027325699105858803,\n",
       " -0.027450473979115486,\n",
       " 0.021086955443024635,\n",
       " -0.02832389809191227,\n",
       " 0.01060586515814066,\n",
       " 0.03718291595578194,\n",
       " -0.014785823412239552,\n",
       " 0.012352713383734226,\n",
       " 0.02083740569651127,\n",
       " -0.02495497651398182,\n",
       " 0.01821713335812092,\n",
       " 0.02308335341513157,\n",
       " 3.216852564946748e-05,\n",
       " -0.0175932589918375,\n",
       " 0.011666451580822468,\n",
       " 0.002994597190991044,\n",
       " 0.017468484118580818,\n",
       " -0.02794957347214222,\n",
       " 0.005864419508725405,\n",
       " 0.013163750059902668,\n",
       " -0.0068626184947788715,\n",
       " 0.014972985722124577,\n",
       " 0.01098018977791071,\n",
       " 0.00879662949591875,\n",
       " -0.004835026804357767,\n",
       " 0.018841007724404335,\n",
       " 0.2854849398136139,\n",
       " -0.0005770838470198214,\n",
       " 0.023332903161644936,\n",
       " -0.003400115529075265,\n",
       " 0.02645227499306202,\n",
       " -0.014536273665726185,\n",
       " -0.0014037174405530095,\n",
       " 0.03543606773018837,\n",
       " 0.012165551073849201,\n",
       " 0.05440184846520424,\n",
       " -0.01721893437206745,\n",
       " -0.0034625029657036066,\n",
       " -0.004273539874702692,\n",
       " -0.023208128288388252,\n",
       " 0.013101362623274326,\n",
       " -0.03942886367440224,\n",
       " 0.03543606773018837,\n",
       " -0.0366838164627552,\n",
       " 0.010356315411627293,\n",
       " -0.020213531330227852,\n",
       " 0.030070746317505836,\n",
       " 0.034936968237161636,\n",
       " 0.0329405702650547,\n",
       " 0.007736042607575655,\n",
       " -0.004086377564817667,\n",
       " 0.03917931392788887,\n",
       " -0.011479289270937443,\n",
       " 0.01060586515814066,\n",
       " 0.021461280062794685,\n",
       " 0.06787753850221634,\n",
       " -0.057645995169878006,\n",
       " 0.0029010160360485315,\n",
       " 0.02420632727444172,\n",
       " -0.007798430044203997,\n",
       " 0.021835604682564735,\n",
       " -0.007580074016004801,\n",
       " -0.000682362646330148,\n",
       " 0.00492860795930028,\n",
       " -0.0344378687441349,\n",
       " 0.008484692312777042,\n",
       " -0.013350912369787693,\n",
       " -0.020712630823254585,\n",
       " 0.05190635100007057,\n",
       " -0.005833225790411234,\n",
       " 0.00455428333953023,\n",
       " 0.04067661240696907,\n",
       " 0.033439669758081436,\n",
       " -0.023582452908158302,\n",
       " 0.006176356691867113,\n",
       " 0.003025790909305215,\n",
       " -0.0084223048761487,\n",
       " 0.0084223048761487,\n",
       " -0.01572163589298725,\n",
       " 0.012664650566875935,\n",
       " -0.024455877020955086,\n",
       " -0.019215332344174385,\n",
       " 0.04441985860466957,\n",
       " -0.0015440891729667783,\n",
       " 0.018466683104634285,\n",
       " -0.0321919210255146,\n",
       " -0.024331102147698402,\n",
       " 0.00023980172409210354,\n",
       " 0.0381811149418354,\n",
       " 0.010293927974998951,\n",
       " -0.022459479048848152,\n",
       " 0.012539875693619251,\n",
       " -0.01934010721743107,\n",
       " 0.013101362623274326,\n",
       " 0.04217391088604927,\n",
       " -0.02383200265467167,\n",
       " -0.026951374486088753,\n",
       " -0.0016142750391736627,\n",
       " 0.024331102147698402,\n",
       " 0.018466683104634285,\n",
       " 0.0005809830618090928,\n",
       " 0.008484692312777042,\n",
       " -0.01934010721743107,\n",
       " -0.011604064144194126,\n",
       " -0.011479289270937443,\n",
       " -0.010855414904654026,\n",
       " 0.028448672965168953,\n",
       " 0.02570362575352192,\n",
       " 0.028947772458195686,\n",
       " 0.027076149359345436,\n",
       " 0.013475687243044376,\n",
       " -0.014848210848867893,\n",
       " 0.016220735386013985,\n",
       " 0.019464882090687752,\n",
       " -0.001926212222315371,\n",
       " 0.03768201544880867,\n",
       " -0.038929764181375504,\n",
       " 0.015222535468637943,\n",
       " 0.04891175404191017,\n",
       " 0.0009046178893186152,\n",
       " -0.019215332344174385,\n",
       " 0.0013725237222388387,\n",
       " 0.01971443183720112,\n",
       " 0.01896578259766102,\n",
       " 0.0011463692644611,\n",
       " 0.0183419082313776,\n",
       " -0.04067661240696907,\n",
       " -0.04017751291394234,\n",
       " -0.008110367693006992,\n",
       " -0.01896578259766102,\n",
       " 0.006145162973552942,\n",
       " 0.038929764181375504,\n",
       " -0.04891175404191017,\n",
       " 0.012352713383734226,\n",
       " -0.018092358484864235,\n",
       " 0.041175711899995804,\n",
       " -0.07137123495340347,\n",
       " 0.015596860088407993,\n",
       " -0.004616670776158571,\n",
       " -0.021336505189538002,\n",
       " 0.023332903161644936,\n",
       " -0.0007408508681692183,\n",
       " 0.01871623285114765,\n",
       " -0.050908152014017105,\n",
       " 0.022459479048848152,\n",
       " -0.026577049866318703,\n",
       " 0.010356315411627293,\n",
       " -0.000869524956215173,\n",
       " 0.01896578259766102,\n",
       " -0.01721893437206745,\n",
       " -0.031568046659231186,\n",
       " 0.029696421697735786,\n",
       " -0.026327500119805336,\n",
       " 0.010418702848255634,\n",
       " 0.023208128288388252,\n",
       " -0.012352713383734226,\n",
       " 0.0002339529019081965,\n",
       " 0.0183419082313776,\n",
       " 0.02682659961283207,\n",
       " 0.021086955443024635,\n",
       " -0.02458065189421177,\n",
       " 0.005490094888955355,\n",
       " 0.017094159498810768,\n",
       " -0.016595060005784035,\n",
       " -0.017468484118580818,\n",
       " 0.052405450493097305,\n",
       " 0.012789425440132618,\n",
       " -0.03244147077202797,\n",
       " 0.029571646824479103,\n",
       " 0.005115770269185305,\n",
       " 0.041175711899995804,\n",
       " 0.01896578259766102,\n",
       " 0.009794828481972218,\n",
       " 0.01796758361160755,\n",
       " 0.018466683104634285,\n",
       " 0.0344378687441349,\n",
       " -0.010356315411627293,\n",
       " 0.01472343597561121,\n",
       " 0.016719834879040718,\n",
       " 0.04142526164650917,\n",
       " 0.03618471696972847,\n",
       " 0.029322097077965736,\n",
       " 0.0017000577645376325,\n",
       " 0.005053382832556963,\n",
       " -0.00717455567792058,\n",
       " 0.012352713383734226,\n",
       " -0.004616670776158571,\n",
       " 0.034936968237161636,\n",
       " 0.04916130378842354,\n",
       " 0.05964239314198494,\n",
       " -0.00954527873545885,\n",
       " 0.0003938207228202373,\n",
       " 0.0029790003318339586,\n",
       " 0.004460702184587717,\n",
       " 0.03768201544880867,\n",
       " -0.028947772458195686,\n",
       " 0.00530293257907033,\n",
       " 0.006893812213093042,\n",
       " 0.02308335341513157,\n",
       " 0.029322097077965736,\n",
       " -0.002027591923251748,\n",
       " -0.0168446097522974,\n",
       " -0.03393876925110817,\n",
       " -0.015409697778522968,\n",
       " -0.0002183560427511111,\n",
       " 0.01871623285114765,\n",
       " 0.026701824739575386,\n",
       " 0.019839206710457802,\n",
       " 0.030445070937275887,\n",
       " -0.028947772458195686,\n",
       " -0.0009436100372113287,\n",
       " -0.01859145797789097,\n",
       " 0.006020388100296259,\n",
       " -0.029322097077965736,\n",
       " -0.019839206710457802,\n",
       " -0.013475687243044376,\n",
       " -0.05215590074658394,\n",
       " -0.012539875693619251,\n",
       " -0.016345510259270668,\n",
       " 0.01859145797789097,\n",
       " 0.0007642461569048464,\n",
       " 0.028074348345398903,\n",
       " 0.00283862859942019,\n",
       " 0.20363260805606842,\n",
       " 0.039678413420915604,\n",
       " -0.0032753406558185816,\n",
       " 0.012165551073849201,\n",
       " -0.0020743825007230043,\n",
       " -0.022459479048848152,\n",
       " -0.004647864494472742,\n",
       " -0.01023154053837061,\n",
       " 0.017094159498810768,\n",
       " 0.022584253922104836,\n",
       " -0.011604064144194126,\n",
       " -0.04092616215348244,\n",
       " 0.0329405702650547,\n",
       " -0.03868021443486214,\n",
       " -0.015971185639500618,\n",
       " -0.04367120936512947,\n",
       " -0.0175932589918375,\n",
       " 0.004616670776158571,\n",
       " 0.02196037955582142,\n",
       " -0.02532930113375187,\n",
       " -0.014785823412239552,\n",
       " 0.0013725237222388387,\n",
       " 0.004835026804357767,\n",
       " 0.06837663799524307,\n",
       " -0.008297530002892017,\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def get_bedrock_embeddings(input_text, model_id=\"amazon.titan-embed-text-v2:0\", region_name=\"ca-central-1\"):\n",
    "    \"\"\"Fetches text embeddings from AWS Bedrock.\"\"\"\n",
    "    bedrock = boto3.client(service_name='bedrock-runtime', region_name=region_name)\n",
    "    \n",
    "    body = json.dumps({\n",
    "        \"inputText\": input_text,\n",
    "        \"dimensions\": 1024,\n",
    "        \"normalize\": True\n",
    "    })\n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body,\n",
    "        modelId=model_id,\n",
    "        accept=\"*/*\",\n",
    "        contentType=\"application/json\"\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response['body'].read())\n",
    "    return response_body.get('embedding', [])\n",
    "\n",
    "get_bedrock_embeddings(\"hello\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3ebcfb5-7fbc-46dc-87be-4307bb9770cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dynamodb_history_table(table_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    Create a DynamoDB table to store the session history if it doesn't already exist.\n",
    "\n",
    "    Args:\n",
    "    table_name (str): The name of the DynamoDB table to create.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \n",
    "    If the table already exists, this function does nothing. Otherwise, it creates a \n",
    "    new table with a key schema based on 'SessionId'.\n",
    "    \"\"\"\n",
    "    # Get the service resource and client.\n",
    "    dynamodb_resource = boto3.resource(\"dynamodb\")\n",
    "    dynamodb_client = boto3.client(\"dynamodb\")\n",
    "    \n",
    "    # Retrieve the list of tables that currently exist.\n",
    "    existing_tables = []\n",
    "    exclusive_start_table_name = None\n",
    "    \n",
    "    while True:\n",
    "        if exclusive_start_table_name:\n",
    "            response = dynamodb_client.list_tables(ExclusiveStartTableName=exclusive_start_table_name)\n",
    "        else:\n",
    "            response = dynamodb_client.list_tables()\n",
    "        \n",
    "        existing_tables.extend(response.get('TableNames', []))\n",
    "        \n",
    "        if 'LastEvaluatedTableName' in response:\n",
    "            exclusive_start_table_name = response['LastEvaluatedTableName']\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    if table_name not in existing_tables:  # Create a new table if it doesn't exist.\n",
    "        # Create the DynamoDB table.\n",
    "        table = dynamodb_resource.create_table(\n",
    "            TableName=table_name,\n",
    "            KeySchema=[{\"AttributeName\": \"SessionId\", \"KeyType\": \"HASH\"}],\n",
    "            AttributeDefinitions=[{\"AttributeName\": \"SessionId\", \"AttributeType\": \"S\"}],\n",
    "            BillingMode=\"PAY_PER_REQUEST\",\n",
    "        )\n",
    "        \n",
    "        # Wait until the table exists.\n",
    "        table.meta.client.get_waiter(\"table_exists\").wait(TableName=table_name)\n",
    "\n",
    "create_dynamodb_history_table(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0534c6b4-0ceb-4bec-a970-bbae53ccb48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets_manager_client = boto3.client(\"secretsmanager\")\n",
    "ssm_client = boto3.client(\"ssm\", region_name=\"ca-central-1\")\n",
    "\n",
    "def get_secret(secret_name, expect_json=True):\n",
    "    global db_secret\n",
    "    if db_secret is None:\n",
    "        try:\n",
    "            response = secrets_manager_client.get_secret_value(SecretId=secret_name)[\"SecretString\"]\n",
    "            db_secret = json.loads(response) if expect_json else response\n",
    "        except json.JSONDecodeError as e:\n",
    "            logger.error(f\"Failed to decode JSON for secret {secret_name}: {e}\")\n",
    "            raise ValueError(f\"Secret {secret_name} is not properly formatted as JSON.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching secret {secret_name}: {e}\")\n",
    "            raise\n",
    "    return db_secret\n",
    "\n",
    "\n",
    "def get_parameter(param_name, cached_var):\n",
    "    \"\"\"\n",
    "    Fetch a parameter value from Systems Manager Parameter Store.\n",
    "    \"\"\"\n",
    "    if cached_var is None:\n",
    "        try:\n",
    "            response = ssm_client.get_parameter(Name=param_name, WithDecryption=True)\n",
    "            cached_var = response[\"Parameter\"][\"Value\"]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching parameter {param_name}: {e}\")\n",
    "            raise\n",
    "    return cached_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf8ee86a-60c3-4cd7-bcee-a304afb2252e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceNotFoundException",
     "evalue": "An error occurred (ResourceNotFoundException) when calling the GetSecretValue operation: Secrets Manager can't find the specified secret.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceNotFoundException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m secrets_raw \u001b[38;5;241m=\u001b[39m \u001b[43msecrets_manager_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_secret_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSecretId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvirt-care-Database-VCI/credentials/rdsDbCredential\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSecretString\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m secrets \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(secrets_raw)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:570\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     )\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/context.py:124\u001b[0m, in \u001b[0;36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[1;32m    123\u001b[0m     hook()\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:1031\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1028\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1029\u001b[0m     )\n\u001b[1;32m   1030\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1031\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mResourceNotFoundException\u001b[0m: An error occurred (ResourceNotFoundException) when calling the GetSecretValue operation: Secrets Manager can't find the specified secret."
     ]
    }
   ],
   "source": [
    "secrets_raw = secrets_manager_client.get_secret_value(SecretId='virt-care-Database-VCI/credentials/rdsDbCredential')[\"SecretString\"]\n",
    "secrets = json.loads(secrets_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e99e385-1583-4a31-bf2c-5f9e6d46907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up basic logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Environment variables\n",
    "DB_SECRET_NAME = \"virt-care-Database-VCI/credentials/rdsDbCredential\" #os.environ[\"SM_DB_CREDENTIALS\"]\n",
    "REGION = \"ca-central-1\" #os.environ[\"REGION\"]\n",
    "RDS_PROXY_ENDPOINT = secrets.get(\"host\") #os.environ[\"RDS_PROXY_ENDPOINT\"]\n",
    "BEDROCK_LLM_PARAM =  \"meta.llama3-8b-instruct-v1:0\" #os.environ[\"BEDROCK_LLM_PARAM\"]\n",
    "EMBEDDING_MODEL_PARAM = \"amazon.titan-embed-text-v2:0\"#os.environ[\"EMBEDDING_MODEL_PARAM\"]\n",
    "TABLE_NAME_PARAM = \"DynamoDB-Conversation-Table\" #os.environ[\"TABLE_NAME_PARAM\"]\n",
    "\n",
    "# AWS Clients\n",
    "secrets_manager_client = boto3.client(\"secretsmanager\")\n",
    "ssm_client = boto3.client(\"ssm\", region_name=REGION)\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=REGION)\n",
    "\n",
    "# Cached resources\n",
    "connection = None\n",
    "db_secret = None\n",
    "BEDROCK_LLM_ID = None\n",
    "EMBEDDING_MODEL_ID = None\n",
    "TABLE_NAME = \"test\"\n",
    "\n",
    "# Cached embeddings instance\n",
    "embeddings = None\n",
    "\n",
    "\n",
    "\n",
    "def initialize_constants():\n",
    "    global BEDROCK_LLM_ID, EMBEDDING_MODEL_ID, TABLE_NAME, embeddings\n",
    "    BEDROCK_LLM_ID = get_parameter(BEDROCK_LLM_PARAM, BEDROCK_LLM_ID)\n",
    "    EMBEDDING_MODEL_ID = get_parameter(EMBEDDING_MODEL_PARAM, EMBEDDING_MODEL_ID)\n",
    "    TABLE_NAME = get_parameter(TABLE_NAME_PARAM, TABLE_NAME)\n",
    "\n",
    "    if embeddings is None:\n",
    "        embeddings = BedrockEmbeddings(\n",
    "            model_id=EMBEDDING_MODEL_ID,\n",
    "            client=bedrock_runtime,\n",
    "            region_name=REGION,\n",
    "        )\n",
    "    \n",
    "    create_dynamodb_history_table(TABLE_NAME)\n",
    "\n",
    "def connect_to_db():\n",
    "    global connection\n",
    "    if connection is None or connection.closed:\n",
    "        try:\n",
    "            secret = get_secret(DB_SECRET_NAME)\n",
    "            connection_params = {\n",
    "                'dbname': secret[\"dbname\"],\n",
    "                'user': secret[\"username\"],\n",
    "                'password': secret[\"password\"],\n",
    "                'host': RDS_PROXY_ENDPOINT,\n",
    "                'port': secret[\"port\"]\n",
    "            }\n",
    "            connection_string = \" \".join([f\"{key}={value}\" for key, value in connection_params.items()])\n",
    "            connection = psycopg2.connect(connection_string)\n",
    "            logger.info(\"Connected to the database!\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to connect to database: {e}\")\n",
    "            if connection:\n",
    "                connection.rollback()\n",
    "                connection.close()\n",
    "            raise\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a07cb-5edd-4561-b19a-76fd1464e8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_system_prompt(case_id):\n",
    "    connection = connect_to_db()\n",
    "    if connection is None:\n",
    "        logger.error(\"No database connection available.\")\n",
    "        return {\n",
    "            \"statusCode\": 500,\n",
    "            \"body\": json.dumps(\"Database connection failed.\")\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        cur = connection.cursor()\n",
    "        \n",
    "        cur.execute(\"\"\"\n",
    "            SELECT system_prompt, case_title,case_type, law_type\n",
    "            FROM \"cases\"\n",
    "            WHERE case_id = %s;\n",
    "        \"\"\", (case_id,))\n",
    "\n",
    "        result = cur.fetchone()\n",
    "        logger.info(f\"Query result: {result}\")\n",
    "        system_prompt = result[0] if result else None\n",
    "\n",
    "        cur.close()\n",
    "\n",
    "        if system_prompt:\n",
    "            logger.info(f\"System prompt for simulation_group_id {case_id} found: {system_prompt}\")\n",
    "        else:\n",
    "            logger.warning(f\"No system prompt found for simulation_group_id {case_id}\")\n",
    "\n",
    "        return system_prompt\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching system prompt: {e}\")\n",
    "        if cur:\n",
    "            cur.close()\n",
    "        connection.rollback()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a06a23c-028c-4421-9ab8-92769827cfba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b3b2b-d340-4c14-ad7e-907a272f72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b99b1-447c-4e6c-80ac-351f2e3577fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "import psycopg2\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_vectorstore(\n",
    "    collection_name: str, \n",
    "    embeddings: BedrockEmbeddings, \n",
    "    dbname: str, \n",
    "    user: str, \n",
    "    password: str, \n",
    "    host: str, \n",
    "    port: int\n",
    ") -> Optional[PGVector]:\n",
    "    \"\"\"\n",
    "    Initialize and return a PGVector instance.\n",
    "    \n",
    "    Args:\n",
    "    collection_name (str): The name of the collection.\n",
    "    embeddings (BedrockEmbeddings): The embeddings instance.\n",
    "    dbname (str): The name of the database.\n",
    "    user (str): The database user.\n",
    "    password (str): The database password.\n",
    "    host (str): The database host.\n",
    "    port (int): The database port.\n",
    "    \n",
    "    Returns:\n",
    "    Optional[PGVector]: The initialized PGVector instance, or None if an error occurred.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        connection_string = (\n",
    "            f\"postgresql+psycopg://{user}:{password}@{host}:{port}/{dbname}\"\n",
    "        )\n",
    "\n",
    "        logger.info(\"Initializing the VectorStore\")\n",
    "        vectorstore = PGVector(\n",
    "            embeddings=embeddings,\n",
    "            collection_name=collection_name,\n",
    "            connection=connection_string,\n",
    "            use_jsonb=True\n",
    "        )\n",
    "\n",
    "        logger.info(\"VectorStore initialized\")\n",
    "        return vectorstore, connection_string\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error initializing vector store: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9775b5dc-8e35-404d-8cfb-f77aa3d63e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "\n",
    "def get_vectorstore_retriever(\n",
    "    llm,\n",
    "    vectorstore_config_dict: Dict[str, str],\n",
    "    embeddings#: BedrockEmbeddings\n",
    ") -> VectorStoreRetriever:\n",
    "    \"\"\"\n",
    "    Retrieve the vectorstore and return the history-aware retriever object.\n",
    "\n",
    "    Args:\n",
    "    llm: The language model instance used to generate the response.\n",
    "    vectorstore_config_dict (Dict[str, str]): The configuration dictionary for the vectorstore, including parameters like collection name, database name, user, password, host, and port.\n",
    "    embeddings (BedrockEmbeddings): The embeddings instance used to process the documents.\n",
    "\n",
    "    Returns:\n",
    "    VectorStoreRetriever: A history-aware retriever instance.\n",
    "    \"\"\"\n",
    "    vectorstore, _ = get_vectorstore(\n",
    "        collection_name=vectorstore_config_dict['collection_name'],\n",
    "        embeddings=embeddings,\n",
    "        dbname=vectorstore_config_dict['dbname'],\n",
    "        user=vectorstore_config_dict['user'],\n",
    "        password=vectorstore_config_dict['password'],\n",
    "        host=vectorstore_config_dict['host'],\n",
    "        port=int(vectorstore_config_dict['port'])\n",
    "    )\n",
    "\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    # Contextualize question and create history-aware retriever\n",
    "    contextualize_q_system_prompt = (\n",
    "        \"\"\"Given a chat history and the latest user question \n",
    "        which might reference context in the chat history, \n",
    "        formulate a standalone response which can be understood \n",
    "        without the chat history, but may make references to past messages as well.\n",
    "        Just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "    )\n",
    "    contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", contextualize_q_system_prompt),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    history_aware_retriever = create_history_aware_retriever(\n",
    "        llm, retriever, contextualize_q_prompt\n",
    "    )\n",
    "\n",
    "    return history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe3d0a0-290d-4d01-85df-91e194cf7a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_id = '550e8400-e29b-41d4-a716-546655480010'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29a9ddd-b079-45fd-a4c4-9cc0c8a28aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Retrieving vectorstore config.\")\n",
    "db_secret = get_secret(DB_SECRET_NAME)\n",
    "vectorstore_config_dict = {\n",
    "            'collection_name': case_id,\n",
    "            'dbname': db_secret[\"dbname\"],\n",
    "            'user': db_secret[\"username\"],\n",
    "            'password': db_secret[\"password\"],\n",
    "            'host': RDS_PROXY_ENDPOINT,\n",
    "            'port': db_secret[\"port\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3af301-41bb-4ae2-b709-1b130f2d149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "def get_response(query: str, llm: ChatBedrock, history_aware_retriever, table_name: str, session_id: str, system_prompt: str) -> dict:\n",
    "    \"\"\"\n",
    "    Generates a response to a query using the LLM and a history-aware retriever to store context.\n",
    "\n",
    "    Args:\n",
    "    - query (str): The student's query string for which a response is needed.\n",
    "    - llm (ChatBedrock): The language model instance used to generate the response.\n",
    "    - history_aware_retriever: The history-aware retriever instance.\n",
    "    - table_name (str): The DynamoDB table name used to store and retrieve chat history.\n",
    "    - session_id (str): The unique identifier for the chat session.\n",
    "    - system_prompt (str): The system prompt to instruct the model.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing the generated response.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up the memory with conversation buffer\n",
    "    memory = ConversationBufferMemory(memory_key=\"messages\", return_messages=True)\n",
    "\n",
    "    # Set up the prompt template\n",
    "    qa_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\\n\\nContext: {context}\")\n",
    "    ])\n",
    "\n",
    "    # Create a retrieval chain with the history-aware retriever\n",
    "    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "    rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "    # Create the conversation chain\n",
    "    conversation_chain = ConversationChain(\n",
    "        llm=llm,\n",
    "        memory=memory,\n",
    "        retriever=rag_chain\n",
    "    )\n",
    "\n",
    "    # Use the conversation chain to generate the response\n",
    "    response = conversation_chain.run(query)\n",
    "\n",
    "    return {\"answer\": response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8b84b67-3a4a-4c8b-8d0a-164a039ebe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Constants\n",
    "LLAMA_3_8B = \"meta.llama3-8b-instruct-v1:0\"\n",
    "LLAMA_3_70B = \"meta.llama3-70b-instruct-v1:0\"\n",
    "MISTRAL_7B = \"mistral.mistral-7b-instruct-v0:2\"\n",
    "MISTRAL_LARGE = \"mistral.mistral-large-2402-v1:0\"\n",
    "LLAMA_3_1_8B = \"meta.llama3-1-8b-instruct-v1:0\"\n",
    "LLAMA_3_1_70B = \"meta.llama3-1-70b-instruct-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a231f27-a446-4fdd-b776-9a19d3c5e932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "case_memory_store = {}\n",
    "\n",
    "def get_memory(case_id):\n",
    "    if case_id not in case_memory_store:\n",
    "        case_memory_store[case_id] = ConversationBufferMemory(return_messages=False, max_length=3)  # Limits history\n",
    "    return case_memory_store[case_id]\n",
    "\n",
    "def answer_prompt(user_prompt, number_of_docs, case_id):\n",
    "    total_start_time = time.time()\n",
    "    answer_start_time = time.time()\n",
    "\n",
    "    embedding = get_bedrock_embeddings(user_prompt)\n",
    "    llm = BedrockLLM(model_id=LLAMA_3_8B)\n",
    "    memory = get_memory(case_id)\n",
    "\n",
    "    # Get system prompt\n",
    "    system_prompt = get_system_prompt(case_id)\n",
    "    print(system_prompt)\n",
    "\n",
    "    #  Updated Prompt Template to enforce single response\n",
    "    custom_prompt = PromptTemplate.from_template(\n",
    "        \"{system_prompt}\\n\\nConversation History:\\n{history}\\n\\nUser: {input}\\nAssistant: (Provide a single response and do not continue the conversation. End your response clearly.)\"\n",
    "    )\n",
    "\n",
    "    # Create ConversationChain with the correct prompt format\n",
    "    conversation_chain = ConversationChain(\n",
    "        llm=llm,\n",
    "        memory=memory,\n",
    "        prompt=custom_prompt.partial(system_prompt=system_prompt)  # Inject system prompt\n",
    "    )\n",
    "\n",
    "    # Get response\n",
    "    answer = conversation_chain.predict(input=user_prompt).strip()  # Ensures clean output\n",
    "\n",
    "    answer_duration = time.time() - answer_start_time\n",
    "    total_duration = time.time() - total_start_time\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"answer_time\": answer_duration,\n",
    "        \"total_time\": total_duration\n",
    "    }\n",
    "\n",
    "def neat_print(response):\n",
    "    print(f\"Answer: {response['answer']}\\n\")\n",
    "    print(\"_________________________________________________________________________________________________________\")\n",
    "    print(f\"answer_time: {response['answer_time']}\\n\")\n",
    "    print(f\"total_time: {response['total_time']}\\n\")\n",
    "\n",
    "case_id = '550e8400-e29b-41d4-a716-546655480010'\n",
    "response = answer_prompt(\"My client (from Toronto) is going through a divorce, they have three children with their wife and has been married for 40 years. My client wants to find out how to keep the possible financial loss to a minimum.\", 5, case_id)\n",
    "response2 = answer_prompt(\"Where does my client live again?\", 5, case_id)\n",
    "\n",
    "neat_print(response)\n",
    "neat_print(response2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd3f5ea-c7f5-42c9-a350-0a49590dad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "case_memory_store = {}\n",
    "\n",
    "def get_memory(case_id):\n",
    "    if case_id not in case_memory_store:\n",
    "        case_memory_store[case_id] = ConversationBufferMemory(return_messages=False, max_length=3)  # Limits history\n",
    "    return case_memory_store[case_id]\n",
    "\n",
    "def answer_prompt(user_prompt, number_of_docs, case_id):\n",
    "    total_start_time = time.time()\n",
    "    answer_start_time = time.time()\n",
    "\n",
    "    embedding = get_bedrock_embeddings(user_prompt)\n",
    "    llm = BedrockLLM(model_id=LLAMA_3_8B)\n",
    "    memory = get_memory(case_id)\n",
    "\n",
    "    # Get system prompt\n",
    "    system_prompt = get_system_prompt(case_id)\n",
    "    print(system_prompt)\n",
    "\n",
    "    #  Updated Prompt Template to enforce single response\n",
    "    custom_prompt = PromptTemplate.from_template(\n",
    "        \"{system_prompt}\\n\\nConversation History:\\n{history}\\n\\nUser: {input}\\nAssistant: (Provide a single response and do not continue the conversation. End your response clearly.)\"\n",
    "    )\n",
    "\n",
    "    # Create ConversationChain with the correct prompt format\n",
    "    conversation_chain = ConversationChain(\n",
    "        llm=llm,\n",
    "        memory=memory,\n",
    "        prompt=custom_prompt.partial(system_prompt=system_prompt)  # Inject system prompt\n",
    "    )\n",
    "\n",
    "    # Get response\n",
    "    answer = conversation_chain.predict(input=user_prompt).strip()  # Ensures clean output\n",
    "\n",
    "    answer_duration = time.time() - answer_start_time\n",
    "    total_duration = time.time() - total_start_time\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"answer_time\": answer_duration,\n",
    "        \"total_time\": total_duration\n",
    "    }\n",
    "\n",
    "def neat_print(response):\n",
    "    print(f\"Answer: {response['answer']}\\n\")\n",
    "    print(\"_________________________________________________________________________________________________________\")\n",
    "    print(f\"answer_time: {response['answer_time']}\\n\")\n",
    "    print(f\"total_time: {response['total_time']}\\n\")\n",
    "\n",
    "case_id = '550e8400-e29b-41d4-a716-546655480010'\n",
    "response = answer_prompt(\"My client (from Toronto) is going through a divorce, they have three children with their wife and has been married for 40 years. My client wants to find out how to keep the possible financial loss to a minimum.\", 5, case_id)\n",
    "response2 = answer_prompt(\"Where does my client live again?\", 5, case_id)\n",
    "\n",
    "neat_print(response)\n",
    "neat_print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c394aa1-43e1-45bf-9875-817e53e8aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "# from langchain.chains import ConversationChain\n",
    "\n",
    "# # Dictionary to store memory per case ID\n",
    "# case_memory_store = {}\n",
    "\n",
    "# def get_memory(case_id):\n",
    "#     \"\"\"Retrieve memory for a given case ID, creating one if it doesn't exist.\"\"\"\n",
    "#     if case_id not in case_memory_store:\n",
    "#         case_memory_store[case_id] = ConversationBufferMemory(return_messages=True)\n",
    "#     return case_memory_store[case_id]\n",
    "\n",
    "# def clear_memory(case_id):\n",
    "#     if case_id in case_memory_store:\n",
    "#         case_memory_store[case_id] = ConversationBufferMemory(return_messages=True)\n",
    "#         return case_memory_store[case_id]\n",
    "\n",
    "# def answer_prompt(user_prompt, number_of_docs, case_id):\n",
    "#     # Record the start times\n",
    "#     total_start_time = time.time()\n",
    "#     answer_start_time = time.time()\n",
    "\n",
    "#     # Initialize the Bedrock Embeddings model\n",
    "#     embedding = get_bedrock_embeddings(user_prompt)\n",
    "\n",
    "#     # Get the LLM we want to invoke\n",
    "#     llm = BedrockLLM(model_id=LLAMA_3_8B)\n",
    "    \n",
    "#     # Retrieve memory for the specific case ID\n",
    "#     memory = get_memory(case_id)\n",
    "\n",
    "#     # Create the conversation chain with LLM and memory\n",
    "#     conversation_chain = ConversationChain(\n",
    "#         llm=llm,\n",
    "#         memory=memory\n",
    "#     )\n",
    "\n",
    "#     # Get assistant's response using conversation chain\n",
    "#     answer = conversation_chain.predict(input=user_prompt)\n",
    "\n",
    "#     # Record the end time and find the duration of the answer only\n",
    "#     answer_end_time = time.time()\n",
    "#     answer_duration = answer_end_time - answer_start_time\n",
    "\n",
    "#     # Record the total processing time\n",
    "#     total_end_time = time.time()\n",
    "#     total_duration = total_end_time - total_start_time\n",
    "\n",
    "#     return {\n",
    "#         \"answer\": answer,\n",
    "#         \"answer_time\": answer_duration,\n",
    "#         \"total_time\": total_duration\n",
    "#     }\n",
    "\n",
    "# # Neatly prints dictionary returned by answer_prompt\n",
    "# def neat_print(response):\n",
    "#     print(f\"Answer: {response['answer']}\\n\")\n",
    "#     print(\"_________________________________________________________________________________________________________\")\n",
    "#     print(f\"answer_time: {response['answer_time']}\\n\")\n",
    "#     print(f\"total_time: {response['total_time']}\\n\")\n",
    "\n",
    "# # Example usage\n",
    "# case_id = '550e8410-e29b-41d4-a716-447755440011'\n",
    "# response = answer_prompt(\"My client (from Toronto) is going through a divorce, they have three children with their wife and has been married for 40 years. My client wants to find out how to keep the possible financial loss to a minimum.\", 5, case_id)\n",
    "\n",
    "# response2 = answer_prompt(\"Where does my client live again?\", 5, case_id)\n",
    "\n",
    "# neat_print(response)\n",
    "# neat_print(response2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22965ed4-e68e-4fb5-8664-ae1326ce75cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# Dictionary to store memory per case ID\n",
    "case_memory_store = {}\n",
    "\n",
    "def get_memory(case_id):\n",
    "    \"\"\"Retrieve memory for a given case ID, creating one if it doesn't exist.\"\"\"\n",
    "    if case_id not in case_memory_store:\n",
    "        case_memory_store[case_id] = ConversationBufferMemory(return_messages=True)\n",
    "    return case_memory_store[case_id]\n",
    "\n",
    "def clear_memory(case_id):\n",
    "    if case_id in case_memory_store:\n",
    "        case_memory_store[case_id] = ConversationBufferMemory(return_messages=True)\n",
    "        return case_memory_store[case_id]\n",
    "\n",
    "def answer_prompt(user_prompt, number_of_docs, case_id):\n",
    "    # Record the start times\n",
    "    total_start_time = time.time()\n",
    "    answer_start_time = time.time()\n",
    "\n",
    "    # Initialize the Bedrock Embeddings model\n",
    "    embedding = get_bedrock_embeddings(user_prompt)\n",
    "\n",
    "    # Get the LLM we want to invoke\n",
    "    llm = BedrockLLM(model_id=LLAMA_3_70B)\n",
    "    \n",
    "    # Retrieve memory for the specific case ID\n",
    "    memory = get_memory(case_id)\n",
    "\n",
    "    # Create the conversation chain with LLM and memory\n",
    "    conversation_chain = ConversationChain(\n",
    "        llm=llm,\n",
    "        memory=memory\n",
    "    )\n",
    "\n",
    "    # Get assistant's response using conversation chain\n",
    "    answer = conversation_chain.predict(input=user_prompt)\n",
    "\n",
    "    # Record the end time and find the duration of the answer only\n",
    "    answer_end_time = time.time()\n",
    "    answer_duration = answer_end_time - answer_start_time\n",
    "\n",
    "    # Record the total processing time\n",
    "    total_end_time = time.time()\n",
    "    total_duration = total_end_time - total_start_time\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"answer_time\": answer_duration,\n",
    "        \"total_time\": total_duration\n",
    "    }\n",
    "\n",
    "# Neatly prints dictionary returned by answer_prompt\n",
    "def neat_print(response):\n",
    "    print(f\"Answer: {response['answer']}\\n\")\n",
    "    print(\"_________________________________________________________________________________________________________\")\n",
    "    print(f\"answer_time: {response['answer_time']}\\n\")\n",
    "    print(f\"total_time: {response['total_time']}\\n\")\n",
    "\n",
    "# Example usage\n",
    "case_id = '550e8410-e29b-41d4-a716-447755440011'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd25928c-81ed-4d61-962c-a38819b24b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = answer_prompt(\"My client (from Toronto) is going through a divorce, they have three children with their wife and has been married for 40 years. My client wants to find out how to keep the possible financial loss to a minimum.\", 5, case_id)\n",
    "\n",
    "#response2 = answer_prompt(\"Where does my client live again?\", 5, case_id)\n",
    "\n",
    "response_new = answer_prompt(\"Where do I live\", 5, case_id)\n",
    "\n",
    "neat_print(response_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74732b56-40ee-4f2a-b31c-68f8e1f7c45a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffe2734d-fbc6-412c-9463-fed8ee1c3556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_prompt(user_prompt, number_of_docs):\n",
    "\n",
    "    # Record the start times\n",
    "    total_start_time = time.time()\n",
    "    answer_start_time = time.time()\n",
    "\n",
    "    # Initialize the Bedrock Embeddings model\n",
    "    # embeddings = BedrockEmbeddings()\n",
    "    embedding = get_bedrock_embeddings(user_prompt)\n",
    "\n",
    "    # docs = get_combined_docs(embedding, number_of_docs)\n",
    "\n",
    "    # divided_docs = split_docs(docs)\n",
    "    # print(len(divided_docs[\"docs\"]))\n",
    "\n",
    "    # documents = format_docs(divided_docs[\"docs\"])\n",
    "\n",
    "    # Get the LLM we want to invoke\n",
    "    llm = BedrockLLM(\n",
    "                        model_id=LLAMA_3_70B\n",
    "                    )\n",
    "    \n",
    "\n",
    "    case_examples = '''Our hope is that an AI tool used by a student in these scenarios would not attempt to solve the issue, as legal matters have infinitely possible outcomes which can be based on many criteria including the personal circumstances of the client.  It would be great however if the tool could provide the student with insights about the legal and factual issues which may be engaged in these circumstances.  This would then help the students think about what legal issues to further research and what factual issues they should be investigating.\n",
    "\n",
    "\n",
    "Case 1 : \n",
    "\n",
    "\n",
    "The first scenario is based more on the student having had at least one interview with the client : \n",
    "\n",
    "\n",
    "Accused is charged with assault causing bodily harm contrary to section 267(b) of the Criminal Code.  Accused was having an argument in a bar with the Victim, and the Victim is claiming that the Accused punched him repeatedly in an unprovoked attack.  Accused versions of events is that he was fairly intoxicated but still had a good sense of what was going on.  Accused remembers that he and Victim argued and then Victim challenged him to a fight.  Accused says he started walking away.  Accused then says Victim then pushed Accused from behind and Accused says he then turned around and punched Victim in the stomach twice to defend himself.\n",
    "\n",
    "\n",
    "LLM should: \n",
    "\n",
    "\n",
    "Hopefully the tool can gather information which sets out the essential elements of proving the offence of assault causing bodily harm:  \n",
    "application of force, \n",
    "intent to apply force, \n",
    "victim not consenting to force, \n",
    "and that harm that is more than trifling\n",
    " \n",
    "Great additional insights provided by the tool would be things like : \n",
    " \n",
    "-assault is an included offence of assault causing bodily harm\n",
    " \n",
    "-the scenario above raises potential defence of self-defence and consent (and maybe set out the requirements of those defences)\n",
    " \n",
    "-that the intoxication is not likely a relevant issue\n",
    " \n",
    "-that there are critical factual issues in this case in terms of who started the physical altercation and the level of force used by the accused in his response\n",
    " \n",
    "By letting the student know about the legal issues, it would likely help the students assess both the case and the factual issues which are relevant.  Even if it just provided basic legal frameworks the students should be looking at for this offence that would be helpful.\n",
    "\n",
    "\n",
    "Case 2 : \n",
    "\n",
    "\n",
    "The second one is a scenario where an intake person at the clinic has some basic information but no details yet : \n",
    "\n",
    "\n",
    "Client lives in Vancouver BC and had family law issues.  She and her husband were married for two years and have one child.  She and the child recently left her husband because he was being abusive to her and their child.  She is seeking some sort of restraining order against her husband to protect her and her child and need some sort of child support because she is not working.\n",
    "\n",
    "\n",
    "LLM should:  \n",
    "\n",
    "\n",
    "In terms of the second scenario, I think we would be looking for a tool to provide some broader information, such as:\n",
    " \n",
    "emergency court applications which are available for a person in these circumstances\n",
    " \n",
    "the basic legal rights of the client and child in these circumstances and\n",
    " \n",
    "maybe even some community resources able to assist in these circumstances'''\n",
    "    # system_prompt = get_system_prompt(case_id)\n",
    "\n",
    "    # history_aware_retriever = get_vectorstore_retriever(\n",
    "    #         llm=llm,\n",
    "    #         vectorstore_config_dict=vectorstore_config_dict,\n",
    "    #         embeddings=embeddings\n",
    "    #     )\n",
    "\n",
    "\n",
    "\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    bucket_name = \"cit-api-citapidataingestionbucket687917c5-mgr4azmebcps\"\n",
    "    file_key = \"system_prompt.txt\"\n",
    "    \n",
    "    # Retrieve latest prompt\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "    retrieved_prompt = response[\"Body\"].read().decode(\"utf-8\")\n",
    "\n",
    " \n",
    "    # system_prompt = \"You are a helpful UBC student advising assistant who answers with kindness while being concise. If the question does not relate to UBC, respond with 'IDK.'\"\n",
    "    # system_prompt = \"\"\"You are a helpful UBC student advising assistant. \n",
    "    #                    Using the documents given to you, consicely answer the user's prompt with kindness. \n",
    "    #                    If the question does not relate to UBC, respond with 'IDK.'\"\"\"\n",
    "\n",
    "    if llm.model_id == LLAMA_3_8B or llm.model_id == LLAMA_3_70B or llm.model_id == LLAMA_3_1_8B or llm.model_id == LLAMA_3_1_70B:\n",
    "        prompt = f'''{retrieved_prompt}\n",
    "\n",
    "    Case date: N/A'''\n",
    "    else:\n",
    "        prompt = f\"\"\"{system_prompt}. Provide your answer as if you are talking to a student.\n",
    "            Here is the question: {user_prompt}\n",
    "            \"\"\"\n",
    "\n",
    "    \n",
    "    answer = llm.invoke(prompt)\n",
    "\n",
    "    # Record the end time and find duration of answer only\n",
    "    answer_end_time = time.time()\n",
    "    answer_duration = answer_end_time - answer_start_time\n",
    "\n",
    "    # check_docs = check_if_documents_relates(divided_docs[\"docs\"], user_prompt, llm)\n",
    "    # check_additional_docs = check_if_documents_relates(divided_docs[\"removed_docs\"], user_prompt, llm)\n",
    "\n",
    "    # Record the end time and find duration of the total time of checking over each document\n",
    "    total_end_time = time.time()\n",
    "    total_duration = total_end_time - total_start_time\n",
    "\n",
    "    return {\"answer\": answer,\n",
    "            # \"docs\": check_docs,\n",
    "            # \"additional_docs\": check_additional_docs,\n",
    "            \"answer_time\": answer_duration, \"total_time\": total_duration}\n",
    "\n",
    "# Neatly prints dictionary returned by answer_prompt\n",
    "def neat_print(response):\n",
    "    print(f\"{response['answer']}\\n\")\n",
    "\n",
    "#response = answer_prompt(\"My client is going through a divorce, they have three children with their wife and has been married for 40 years. My client wants to find out how to keep the possible financial loss to a minimum.\", 5)\n",
    "# response = answer_prompt(\"Accused is charged with assault causing bodily harm contrary to section 267(b) of the Criminal Code.  Accused was having an argument in a bar with the Victim, and the Victim is claiming that the Accused punched him repeatedly in an unprovoked attack.  Accused versions of events is that he was fairly intoxicated but still had a good sense of what was going on.  Accused remembers that he and Victim argued and then Victim challenged him to a fight.  Accused says he started walking away.  Accused then says Victim then pushed Accused from behind and Accused says he then turned around and punched Victim in the stomach twice to defend himself.\", 5)\n",
    "\n",
    "# neat_print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef1679bc-ba8c-49dd-bc91-418bbe049889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "You are helping me, the law student, analyze this case.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assault_case_details = \"\"\"Accused is charged with assault causing bodily harm contrary to section 267(b) of the Criminal Code.  \n",
    "Accused was having an argument in a bar with the Victim, and the Victim is claiming that the Accused punched him repeatedly in an unprovoked attack.  \n",
    "Accused versions of events is that he was fairly intoxicated but still had a good sense of what was going on.  \n",
    "Accused remembers that he and Victim argued and then Victim challenged him to a fight.  \n",
    "Accused says he started walking away.  \n",
    "Accused then says Victim then pushed Accused from behind and Accused says he then turned around and punched Victim in the stomach twice to defend himself.\n",
    "\"\"\"\n",
    "\n",
    "assault_case_response = answer_prompt(assault_case_details, 5)\n",
    "\n",
    "neat_print(assault_case_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "07752f65-beab-4110-bd76-55122f6cf167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:langchain_aws.llms.bedrock:Using Bedrock Invoke API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                Based on the information provided, it appears that the client is seeking a restraining order and child support due to domestic violence. In British Columbia, the client may be eligible for an Emergency Protection Order (EPO) or a Restraining Order (RO) under the Family Law Act. An EPO is a temporary order that can be obtained quickly, usually within 24 hours, to provide immediate protection for the client and her child. An RO is a longer-term order that can provide ongoing protection and support.\n",
      "\n",
      "                In terms of child support, the client may be eligible for support under the Family Maintenance Enforcement Program (FMEP) or through a court order. The client should also be aware that she may be eligible for other forms of support, such as spousal support, and that she should seek legal advice to determine her options.\n",
      "\n",
      "                Additionally, the client may want to consider seeking support from local community resources, such as the Vancouver Women's Transition House or the BC Society for Male Survivors of Child Abuse, which provide support and resources for individuals and families affected by domestic violence.\n",
      "\n",
      "                Possible follow-up questions for the client:\n",
      "                1. Can you provide more information about the abuse you and your child experienced, including any incidents, threats, or intimidation?\n",
      "                2. Have you already taken any steps to leave the relationship, such as changing your locks or getting a new phone number?\n",
      "                3. Do you have any documentation or evidence of the abuse, such as police reports, medical records, or photos?\n",
      "                4. Have you spoken to any family or friends about the abuse, and if so, have they been supportive?\n",
      "                5. Are there any specific concerns you have about your child's well-being or safety in the current situation?\n",
      "\n",
      "                Please note that these questions are not intended for the client to ask a lawyer, but rather for the law student to ask the client to gather more information and assess the situation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "restraining_order_case_details = \"\"\"\n",
    "                                Client lives in Vancouver, BC, and has family\n",
    "                                law issues. She and her husband were married\n",
    "                                for two years and have one child. She and the\n",
    "                                child recently left her husband because he was\n",
    "                                being abusive to her and their child. She is\n",
    "                                seeking some sort of restraining order against\n",
    "                                her husband to protect herself and her child\n",
    "                                and needs some form of child support because\n",
    "                                she is not working.\n",
    "                                \"\"\"\n",
    "\n",
    "restraining_order_case_response = answer_prompt(restraining_order_case_details, 5)\n",
    "\n",
    "neat_print(restraining_order_case_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "6cefb22d-8a8c-4d5d-8e7c-c675779480aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_details = \"\"\"Accused is charged with assault causing bodily harm contrary to section 267(b) of the Criminal Code.  \n",
    "Accused was having an argument in a bar with the Victim, and the Victim is claiming that the Accused punched him repeatedly in an unprovoked attack.  \n",
    "Accused versions of events is that he was fairly intoxicated but still had a good sense of what was going on.  \n",
    "Accused remembers that he and Victim argued and then Victim challenged him to a fight.  \n",
    "Accused says he started walking away.  \n",
    "Accused then says Victim then pushed Accused from behind and Accused says he then turned around and punched Victim in the stomach twice to defend himself.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "dd2345d7-cc44-4f35-92f1-ed6b647ee831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE_NAME: test\n"
     ]
    }
   ],
   "source": [
    "print(f\"TABLE_NAME: {TABLE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c0bc030b-3ff7-4906-af36-6784d7727ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:langchain_aws.llms.bedrock:Using Bedrock Invoke API to generate response\n"
     ]
    }
   ],
   "source": [
    "response3 = answer_prompt(\"What was the third possible question you said I could ask my client?\", 5, case_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5f4025bc-7bf8-44d7-ba01-12c1a5b6894f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': ' Ah, the third possible question I suggested your client could ask themselves is \"Consider a separation agreement\". This can help outline the terms of the separation, including child custody, child support, and spousal support, which can reduce uncertainty and potential disputes.',\n",
       " 'answer_time': 0.7696671485900879,\n",
       " 'total_time': 0.7696688175201416}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d03c13c0-1ad8-4ca8-9f0b-7dd14c8ac91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_output_assault = \"\"\" Hi there, I'd be happy to help you analyze this case. Based on the information provided, it appears that the accused is charged with assault causing bodily harm under section 267(b) of the Criminal Code. \n",
    "                         To prove the offence of assault causing bodily harm, the prosecution must establish the essential elements, which include: \n",
    "                         1. The application of force;\n",
    "                         2. The intent to apply force;\n",
    "                         3. The victim did not consent to the force;\n",
    "                         4. And that the harm caused was more than trifling. \n",
    "                         In this case, the victim claims that the accused punched him repeatedly in an unprovoked attack, which may suggest that the accused did not have a reasonable belief in the need to defend himself. \n",
    "                         However, the accused's version of events suggests that he was pushed from behind by the victim and that he punched the victim in self-defense. \n",
    "                         This raises potential defences of self-defence and consent, which the accused may be able to argue. \n",
    "                         It's also important to note that the accused's intoxication may not be a relevant issue in this case. \n",
    "                         There are also critical factual issues in this case, such as who started the physical altercation and the level of force used by the accused in his response. \n",
    "                         Some potential follow-up questions you could ask the client to clarify the facts include:\n",
    "                         1. Can you describe the argument that occurred before the physical altercation?\n",
    "                         2. Did you see the victim push you from behind before you punched him?\n",
    "                         3. How did you feel after being pushed from behind? Did you feel threatened or scared?\n",
    "                         4. Did you try to de-escalate the situation before punching the victim?\n",
    "                         5. Can you describe the level of force you used when punching the victim?\n",
    "                         I hope this helps! Let me know if you have any other questions or if there's anything else I can help with.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b0a824ba-e78a-4937-9fd6-6682c1bacb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hi there, I'd be happy to help you analyze this case. Based on the information provided, it appears that the accused is charged with assault causing bodily harm under section 267(b) of the Criminal Code. \n",
      "                 To prove the offence of assault causing bodily harm, the prosecution must establish the essential elements, which include: \n",
      "                 1. The application of force;\n",
      "                 2. The intent to apply force;\n",
      "                 3. The victim did not consent to the force;\n",
      "                 4. And that the harm caused was more than trifling. \n",
      "                 In this case, the victim claims that the accused punched him repeatedly in an unprovoked attack, which may suggest that the accused did not have a reasonable belief in the need to defend himself. \n",
      "                 However, the accused's version of events suggests that he was pushed from behind by the victim and that he punched the victim in self-defense. \n",
      "                 This raises potential defences of self-defence and consent, which the accused may be able to argue. \n",
      "                 It's also important to note that the accused's intoxication may not be a relevant issue in this case. \n",
      "                 There are also critical factual issues in this case, such as who started the physical altercation and the level of force used by the accused in his response. \n",
      "                 Some potential follow-up questions you could ask the client to clarify the facts include:\n",
      "                 1. Can you describe the argument that occurred before the physical altercation?\n",
      "                 2. Did you see the victim push you from behind before you punched him?\n",
      "                 3. How did you feel after being pushed from behind? Did you feel threatened or scared?\n",
      "                 4. Did you try to de-escalate the situation before punching the victim?\n",
      "                 5. Can you describe the level of force you used when punching the victim?\n",
      "                 I hope this helps! Let me know if you have any other questions or if there's anything else I can help with.\n"
     ]
    }
   ],
   "source": [
    "print(sample_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "239c3d45-e9b8-4da9-bca5-b3436a5d5041",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_output_restraining = \"\"\"\n",
    "                            Hi! Thank you for sharing this information with me. It sounds like a very \n",
    "                            serious and sensitive situation.\n",
    "                            \n",
    "                            Based on the information you've provided, it seems that the client is seeking \n",
    "                            a restraining order and child support due to domestic violence. In British \n",
    "                            Columbia, the client may be eligible for an Emergency Protection Order (EPO) \n",
    "                            or a Restraining Order (RO) under the Family Law Act.\n",
    "                            \n",
    "                            An EPO is a court order that can be obtained quickly, usually within 24 hours, \n",
    "                            to provide immediate protection for the client and her child. A RO, on the \n",
    "                            other hand, is a longer-term order that can provide ongoing protection and \n",
    "                            support for the client and her child.\n",
    "                            \n",
    "                            In terms of child support, the client may be eligible for support under the \n",
    "                            Family Maintenance Enforcement Program (FMEP) or through a court order. It's \n",
    "                            also important to note that the client may be eligible for other forms of \n",
    "                            support, such as counseling or legal aid, to help her and her child navigate \n",
    "                            this difficult situation.\n",
    "                            \n",
    "                            What would you like to know more about or discuss further? Are there any \n",
    "                            specific concerns or questions the client has about the restraining order or \n",
    "                            child support process? Please let me know and I'll do my best to provide more \n",
    "                            information and guidance.\n",
    "                            \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "778f2a33-4378-4ed3-8f8b-72597803fdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            Hi! Thank you for sharing this information with me. It sounds like a very \n",
      "                            serious and sensitive situation.\n",
      "                            \n",
      "                            Based on the information you've provided, it seems that the client is seeking \n",
      "                            a restraining order and child support due to domestic violence. In British \n",
      "                            Columbia, the client may be eligible for an Emergency Protection Order (EPO) \n",
      "                            or a Restraining Order (RO) under the Family Law Act.\n",
      "                            \n",
      "                            An EPO is a court order that can be obtained quickly, usually within 24 hours, \n",
      "                            to provide immediate protection for the client and her child. A RO, on the \n",
      "                            other hand, is a longer-term order that can provide ongoing protection and \n",
      "                            support for the client and her child.\n",
      "                            \n",
      "                            In terms of child support, the client may be eligible for support under the \n",
      "                            Family Maintenance Enforcement Program (FMEP) or through a court order. It's \n",
      "                            also important to note that the client may be eligible for other forms of \n",
      "                            support, such as counseling or legal aid, to help her and her child navigate \n",
      "                            this difficult situation.\n",
      "                            \n",
      "                            What would you like to know more about or discuss further? Are there any \n",
      "                            specific concerns or questions the client has about the restraining order or \n",
      "                            child support process? Please let me know and I'll do my best to provide more \n",
      "                            information and guidance.\n",
      "                            \n"
     ]
    }
   ],
   "source": [
    "print(sample_output_restraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "686ecf2d-41ac-4992-b3a8-6479b2ad9268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lm-format-enforcer\n",
      "  Downloading lm_format_enforcer-0.10.11-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting interegular>=0.3.2 (from lm-format-enforcer)\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lm-format-enforcer) (24.2)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lm-format-enforcer) (2.10.6)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lm-format-enforcer) (6.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=1.10.8->lm-format-enforcer) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=1.10.8->lm-format-enforcer) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=1.10.8->lm-format-enforcer) (4.12.2)\n",
      "Downloading lm_format_enforcer-0.10.11-py3-none-any.whl (44 kB)\n",
      "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Installing collected packages: interegular, lm-format-enforcer\n",
      "Successfully installed interegular-0.3.3 lm-format-enforcer-0.10.11\n"
     ]
    }
   ],
   "source": [
    "!pip install lm-format-enforcer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae858115-9fa0-48ef-a2ee-813480baed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers[torch]\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers[torch]) (3.17.0)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers[torch])\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers[torch]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers[torch])\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers[torch])\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers[torch]) (4.67.1)\n",
      "Collecting torch>=2.0 (from transformers[torch])\n",
      "  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting accelerate>=0.26.0 (from transformers[torch])\n",
      "  Downloading accelerate-1.5.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from accelerate>=0.26.0->transformers[torch]) (6.1.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (2025.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (3.1.5)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0->transformers[torch])\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0->transformers[torch])\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0->transformers[torch])\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->transformers[torch])\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->transformers[torch])\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->transformers[torch])\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->transformers[torch])\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->transformers[torch])\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->transformers[torch])\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch>=2.0->transformers[torch])\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.0->transformers[torch])\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.0->transformers[torch])\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->transformers[torch])\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch>=2.0->transformers[torch])\n",
      "  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=2.0->transformers[torch])\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers[torch]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers[torch]) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch>=2.0->transformers[torch]) (3.0.2)\n",
      "Downloading accelerate-1.5.2-py3-none-any.whl (345 kB)\n",
      "Downloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: triton, nvidia-cusparselt-cu12, sympy, safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, accelerate\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "Successfully installed accelerate-1.5.2 huggingface-hub-0.29.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 safetensors-0.5.3 sympy-1.13.1 tokenizers-0.21.1 torch-2.6.0 transformers-4.49.0 triton-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b3cd4d1-52af-40a2-bf2f-b9c7f0b6220c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepeval\n",
      "  Downloading deepeval-2.5.6-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepeval) (3.11.12)\n",
      "Requirement already satisfied: black in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepeval) (25.1.0)\n",
      "Requirement already satisfied: coverage in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepeval) (7.6.12)\n",
      "Collecting grpcio<2.0.0,>=1.67.1 (from deepeval)\n",
      "  Downloading grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting instructor (from deepeval)\n",
      "  Downloading instructor-1.7.5-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: langchain_community in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepeval) (0.3.19)\n",
      "Collecting langchain_openai (from deepeval)\n",
      "  Downloading langchain_openai-0.3.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting llama-index (from deepeval)\n",
      "  Downloading llama_index-0.12.24-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting ollama (from deepeval)\n",
      "  Downloading ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting openai (from deepeval)\n",
      "  Downloading openai-1.66.3-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.24.0 (from deepeval)\n",
      "  Downloading opentelemetry_api-1.31.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 (from deepeval)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.24.0 (from deepeval)\n",
      "  Downloading opentelemetry_sdk-1.31.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting portalocker (from deepeval)\n",
      "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pytest<8.0.0,>=7.4.3 (from deepeval)\n",
      "  Downloading pytest-7.4.4-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting pytest-asyncio<0.22.0,>=0.21.1 (from deepeval)\n",
      "  Downloading pytest_asyncio-0.21.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pytest-repeat (from deepeval)\n",
      "  Downloading pytest_repeat-0.9.3-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting pytest-rerunfailures<13.0,>=12.0 (from deepeval)\n",
      "  Downloading pytest_rerunfailures-12.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting pytest-xdist (from deepeval)\n",
      "  Downloading pytest_xdist-3.6.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepeval) (2.32.3)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepeval) (13.9.4)\n",
      "Collecting sentry-sdk<2.0.0,>=1.33.1 (from deepeval)\n",
      "  Downloading sentry_sdk-1.45.1-py2.py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepeval) (75.8.0)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepeval) (0.9.0)\n",
      "Requirement already satisfied: tenacity<=9.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepeval) (9.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepeval) (4.67.1)\n",
      "Collecting twine==5.1.1 (from deepeval)\n",
      "  Downloading twine-5.1.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typer (from deepeval)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepeval) (0.45.1)\n",
      "Requirement already satisfied: pkginfo>=1.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from twine==5.1.1->deepeval) (1.12.0)\n",
      "Collecting readme-renderer>=35.0 (from twine==5.1.1->deepeval)\n",
      "  Downloading readme_renderer-44.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: requests-toolbelt!=0.9.0,>=0.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from twine==5.1.1->deepeval) (1.0.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from twine==5.1.1->deepeval) (2.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from twine==5.1.1->deepeval) (6.11.0)\n",
      "Requirement already satisfied: keyring>=15.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from twine==5.1.1->deepeval) (25.6.0)\n",
      "Collecting rfc3986>=1.4.0 (from twine==5.1.1->deepeval)\n",
      "  Downloading rfc3986-2.0.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting pkginfo>=1.8.1 (from twine==5.1.1->deepeval)\n",
      "  Downloading pkginfo-1.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.24.0->deepeval) (1.2.18)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\n",
      "  Downloading googleapis_common_protos-1.69.1-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\n",
      "  Downloading opentelemetry_proto-1.31.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: protobuf<6.0,>=5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-proto==1.31.0->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (5.29.3)\n",
      "Collecting opentelemetry-semantic-conventions==0.52b0 (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval)\n",
      "  Downloading opentelemetry_semantic_conventions-0.52b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval) (4.12.2)\n",
      "Requirement already satisfied: iniconfig in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pytest<8.0.0,>=7.4.3->deepeval) (2.0.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pytest<8.0.0,>=7.4.3->deepeval) (24.2)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pytest<8.0.0,>=7.4.3->deepeval) (1.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pytest<8.0.0,>=7.4.3->deepeval) (1.2.2)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pytest<8.0.0,>=7.4.3->deepeval) (2.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->deepeval) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->deepeval) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->deepeval) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich<14.0.0,>=13.6.0->deepeval) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich<14.0.0,>=13.6.0->deepeval) (2.19.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->deepeval) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->deepeval) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->deepeval) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->deepeval) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->deepeval) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->deepeval) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->deepeval) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->deepeval) (1.18.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from black->deepeval) (8.1.8)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from black->deepeval) (1.0.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from black->deepeval) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from black->deepeval) (4.3.6)\n",
      "Collecting docstring-parser<1.0,>=0.16 (from instructor->deepeval)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from instructor->deepeval) (3.1.5)\n",
      "Collecting jiter<0.9,>=0.6.1 (from instructor->deepeval)\n",
      "  Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from instructor->deepeval) (2.27.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from instructor->deepeval) (2.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai->deepeval) (4.8.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai->deepeval)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai->deepeval) (0.28.1)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai->deepeval) (1.3.1)\n",
      "Collecting shellingham>=1.3.0 (from typer->deepeval)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain_community->deepeval) (0.3.45)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.20 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain_community->deepeval) (0.3.20)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain_community->deepeval) (2.0.38)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain_community->deepeval) (6.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain_community->deepeval) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain_community->deepeval) (2.8.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain_community->deepeval) (0.3.15)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain_community->deepeval) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain_community->deepeval) (1.26.4)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai->deepeval)\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl.metadata (727 bytes)\n",
      "Collecting llama-index-cli<0.5.0,>=0.4.1 (from llama-index->deepeval)\n",
      "  Downloading llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.24 (from llama-index->deepeval)\n",
      "  Downloading llama_index_core-0.12.24.post1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.6.9-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_llms_openai-0.3.25-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_readers_file-0.4.6-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index->deepeval)\n",
      "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index->deepeval) (3.9.1)\n",
      "Collecting execnet>=2.1 (from pytest-xdist->deepeval)\n",
      "  Downloading execnet-2.1.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community->deepeval) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community->deepeval) (0.9.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.24.0->deepeval) (1.17.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->deepeval) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->deepeval) (0.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata>=3.6->twine==5.1.1->deepeval) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2<4.0.0,>=3.1.4->instructor->deepeval) (3.0.2)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keyring>=15.1->twine==5.1.1->deepeval) (3.3.3)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keyring>=15.1->twine==5.1.1->deepeval) (0.8.0)\n",
      "Requirement already satisfied: jaraco.classes in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keyring>=15.1->twine==5.1.1->deepeval) (3.4.0)\n",
      "Requirement already satisfied: jaraco.functools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keyring>=15.1->twine==5.1.1->deepeval) (4.1.0)\n",
      "Requirement already satisfied: jaraco.context in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keyring>=15.1->twine==5.1.1->deepeval) (6.0.1)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.20->langchain_community->deepeval) (0.3.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community->deepeval) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain_community->deepeval) (3.10.15)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain_community->deepeval) (0.23.0)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.24->llama-index->deepeval)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.24->llama-index->deepeval)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.24->llama-index->deepeval) (2025.2.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.24->llama-index->deepeval) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.24->llama-index->deepeval) (3.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.24->llama-index->deepeval) (11.1.0)\n",
      "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->deepeval)\n",
      "  Downloading llama_cloud-0.1.14-py3-none-any.whl.metadata (902 bytes)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (4.13.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (1.5.3)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval)\n",
      "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->deepeval)\n",
      "  Downloading llama_parse-0.6.4.post1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.6.0->deepeval) (0.1.2)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk>3.8.1->llama-index->deepeval) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk>3.8.1->llama-index->deepeval) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.8.0->instructor->deepeval) (0.7.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community->deepeval) (1.0.1)\n",
      "Collecting nh3>=0.2.14 (from readme-renderer>=35.0->twine==5.1.1->deepeval)\n",
      "  Downloading nh3-0.2.21-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting docutils>=0.21.2 (from readme-renderer>=35.0->twine==5.1.1->deepeval)\n",
      "  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community->deepeval) (3.1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (2.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain_community->deepeval) (3.0.0)\n",
      "Collecting llama-cloud-services>=0.6.4 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->deepeval)\n",
      "  Downloading llama_cloud_services-0.6.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: cryptography>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from SecretStorage>=3.2->keyring>=15.1->twine==5.1.1->deepeval) (44.0.1)\n",
      "Requirement already satisfied: more_itertools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jaraco.classes->keyring>=15.1->twine==5.1.1->deepeval) (10.6.0)\n",
      "Requirement already satisfied: backports.tarfile in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jaraco.context->keyring>=15.1->twine==5.1.1->deepeval) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (2025.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine==5.1.1->deepeval) (1.17.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (1.17.0)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine==5.1.1->deepeval) (2.22)\n",
      "Downloading deepeval-2.5.6-py3-none-any.whl (567 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m567.8/567.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading twine-5.1.1-py3-none-any.whl (38 kB)\n",
      "Downloading grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading opentelemetry_api-1.31.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.31.0-py3-none-any.whl (55 kB)\n",
      "Downloading opentelemetry_sdk-1.31.0-py3-none-any.whl (118 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.52b0-py3-none-any.whl (183 kB)\n",
      "Downloading pytest-7.4.4-py3-none-any.whl (325 kB)\n",
      "Downloading pytest_asyncio-0.21.2-py3-none-any.whl (13 kB)\n",
      "Downloading pytest_rerunfailures-12.0-py3-none-any.whl (12 kB)\n",
      "Downloading sentry_sdk-1.45.1-py2.py3-none-any.whl (267 kB)\n",
      "Downloading instructor-1.7.5-py3-none-any.whl (83 kB)\n",
      "Downloading openai-1.66.3-py3-none-any.whl (567 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m567.4/567.4 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Downloading langchain_openai-0.3.8-py3-none-any.whl (55 kB)\n",
      "Downloading llama_index-0.12.24-py3-none-any.whl (7.0 kB)\n",
      "Downloading ollama-0.4.7-py3-none-any.whl (13 kB)\n",
      "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
      "Downloading pytest_repeat-0.9.3-py3-none-any.whl (4.2 kB)\n",
      "Downloading pytest_xdist-3.6.1-py3-none-any.whl (46 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading execnet-2.1.1-py3-none-any.whl (40 kB)\n",
      "Downloading googleapis_common_protos-1.69.1-py2.py3-none-any.whl (293 kB)\n",
      "Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_core-0.12.24.post1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.6.9-py3-none-any.whl (14 kB)\n",
      "Downloading llama_index_llms_openai-0.3.25-py3-none-any.whl (16 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.4.6-py3-none-any.whl (40 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading pkginfo-1.10.0-py3-none-any.whl (30 kB)\n",
      "Downloading readme_renderer-44.0-py3-none-any.whl (13 kB)\n",
      "Downloading rfc3986-2.0.0-py2.py3-none-any.whl (31 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading docutils-0.21.2-py3-none-any.whl (587 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m587.4/587.4 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading llama_cloud-0.1.14-py3-none-any.whl (261 kB)\n",
      "Downloading llama_parse-0.6.4.post1-py3-none-any.whl (4.9 kB)\n",
      "Downloading nh3-0.2.21-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m739.0/739.0 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading llama_cloud_services-0.6.5-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: striprtf, filetype, dirtyjson, shellingham, sentry-sdk, rfc3986, pytest, pypdf, portalocker, pkginfo, opentelemetry-proto, nh3, jiter, grpcio, googleapis-common-protos, execnet, docutils, docstring-parser, distro, tiktoken, readme-renderer, pytest-xdist, pytest-rerunfailures, pytest-repeat, pytest-asyncio, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, typer, opentelemetry-semantic-conventions, openai, ollama, llama-cloud, opentelemetry-sdk, llama-index-core, instructor, twine, opentelemetry-exporter-otlp-proto-grpc, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, langchain_openai, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index, deepeval\n",
      "  Attempting uninstall: pytest\n",
      "    Found existing installation: pytest 8.3.4\n",
      "    Uninstalling pytest-8.3.4:\n",
      "      Successfully uninstalled pytest-8.3.4\n",
      "  Attempting uninstall: pkginfo\n",
      "    Found existing installation: pkginfo 1.12.0\n",
      "    Uninstalling pkginfo-1.12.0:\n",
      "      Successfully uninstalled pkginfo-1.12.0\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.16\n",
      "    Uninstalling docutils-0.16:\n",
      "      Successfully uninstalled docutils-0.16\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.38.6 requires docutils<0.17,>=0.10, but you have docutils 0.21.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed deepeval-2.5.6 dirtyjson-1.0.8 distro-1.9.0 docstring-parser-0.16 docutils-0.21.2 execnet-2.1.1 filetype-1.2.0 googleapis-common-protos-1.69.1 grpcio-1.71.0 instructor-1.7.5 jiter-0.8.2 langchain_openai-0.3.8 llama-cloud-0.1.14 llama-cloud-services-0.6.5 llama-index-0.12.24 llama-index-agent-openai-0.4.6 llama-index-cli-0.4.1 llama-index-core-0.12.24.post1 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.9 llama-index-llms-openai-0.3.25 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.6 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.4.post1 nh3-0.2.21 ollama-0.4.7 openai-1.66.3 opentelemetry-api-1.31.0 opentelemetry-exporter-otlp-proto-common-1.31.0 opentelemetry-exporter-otlp-proto-grpc-1.31.0 opentelemetry-proto-1.31.0 opentelemetry-sdk-1.31.0 opentelemetry-semantic-conventions-0.52b0 pkginfo-1.10.0 portalocker-3.1.1 pypdf-5.4.0 pytest-7.4.4 pytest-asyncio-0.21.2 pytest-repeat-0.9.3 pytest-rerunfailures-12.0 pytest-xdist-3.6.1 readme-renderer-44.0 rfc3986-2.0.0 sentry-sdk-1.45.1 shellingham-1.5.4 striprtf-0.0.26 tiktoken-0.9.0 twine-5.1.1 typer-0.15.2\n"
     ]
    }
   ],
   "source": [
    "!pip install deepeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bf065d0-f59b-4c02-90b6-1f482b6daff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import transformers\n",
    "from pydantic import BaseModel\n",
    "from lmformatenforcer import JsonSchemaParser\n",
    "# from lmformatenforcer.integrations.transformers import (\n",
    "#     build_transformers_prefix_allowed_tokens_fn,\n",
    "# )\n",
    "\n",
    "from deepeval.models import DeepEvalBaseLLM\n",
    "\n",
    "\n",
    "class CustomLlama3_70B(DeepEvalBaseLLM):\n",
    "    ...\n",
    "\n",
    "    def __init__(self):\n",
    "        llm = BedrockLLM(model_id=LLAMA_3_70B)        \n",
    "        self.model = llm\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        # Get the LLM we want to invoke\n",
    "        llm = self.load_model()\n",
    "\n",
    "\n",
    "        llm = BedrockLLM(\n",
    "            model_id=LLAMA_3_8B,\n",
    "            streaming=True\n",
    "                    )\n",
    "    \n",
    "\n",
    "        s3 = boto3.client(\"s3\")\n",
    "        bucket_name = \"cit-api-citapidataingestionbucket687917c5-mgr4azmebcps\"\n",
    "        file_key = \"system_prompt.txt\"\n",
    "        \n",
    "        # Retrieve latest prompt\n",
    "        response = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "        retrieved_prompt = response[\"Body\"].read().decode(\"utf-8\")\n",
    "    \n",
    "     \n",
    "        # system_prompt = \"You are a helpful UBC student advising assistant who answers with kindness while being concise. If the question does not relate to UBC, respond with 'IDK.'\"\n",
    "        # system_prompt = \"\"\"You are a helpful UBC student advising assistant. \n",
    "        #                    Using the documents given to you, consicely answer the user's prompt with kindness. \n",
    "        #                    If the question does not relate to UBC, respond with 'IDK.'\"\"\"\n",
    "    \n",
    "        if llm.model_id == LLAMA_3_8B or llm.model_id == LLAMA_3_70B or llm.model_id == LLAMA_3_1_8B or llm.model_id == LLAMA_3_1_70B:\n",
    "            prompt = f'''{retrieved_prompt}\n",
    "    \n",
    "        Case date: N/A'''\n",
    "        else:\n",
    "            prompt = f\"\"\"{system_prompt}. Provide your answer as if you are talking to a student.\n",
    "                Here is the question: {user_prompt}\n",
    "                \"\"\"\n",
    "            \n",
    "        # Retrieve memory for the specific case ID\n",
    "            \n",
    "        # Get assistant's response using conversation chain\n",
    "        answer = llm.invoke(input=prompt)\n",
    "        \n",
    "        # Create parser required for JSON confinement using lmformatenforcer\n",
    "        #parser = JsonSchemaParser(schema.model_json_schema())\n",
    "        # prefix_function = build_transformers_prefix_allowed_tokens_fn(\n",
    "        #     pipeline.tokenizer, parser\n",
    "        # )\n",
    "        \n",
    "        # Output and load valid JSON\n",
    "        # output_dict = pipeline(prompt, prefix_allowed_tokens_fn=prefix_function)\n",
    "        # output = output_dict[0][\"generated_text\"][len(prompt) :]\n",
    "        # json_result = json.loads(output)\n",
    "        \n",
    "        # Return valid JSON object according to the schema DeepEval supplied\n",
    "        return answer # schema(**json_result)\n",
    "\n",
    "    async def a_generate(self, prompt: str, schema: BaseModel) -> BaseModel:\n",
    "        return self.generate(prompt, schema)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"Llama 3.1 70B\"\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc3a4e01-a7d3-4236-bbcc-c88707da4fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel = CustomLlama3_70B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7dea60b5-fb16-493f-9987-b1a5353fa7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Client's age: 25\n",
      "        Client's occupation: Student\n",
      "        Client's injuries: Sprained ankle, bruised knee\n",
      "        Client's medical expenses: $1,000\n",
      "        Client's lost wages: $2,000\n",
      "        Client's other expenses: $500\n",
      "        Client's total damages: $3,500\n",
      "        Defendant's (McDonald's) insurance coverage: $1,000,000\n",
      "        Defendant's (Apple) involvement: Apple owns McDonald's in Manitoba, but the client slipped and fell in a McDonald's that is not owned by Apple. Apple has no direct connection to the incident.\n",
      "\n",
      "Please provide legal context and analysis, relevant issues, possible strategies to defend the client, and other important details in a structured natural language response. Also, provide possible follow-up questions for me, the law student, to ask the client to help progress the case more after your initial analysis.\n",
      "\n",
      "Please keep in mind that this is a hypothetical case and not a real one.\n"
     ]
    }
   ],
   "source": [
    "# response_eval = testmodel.generate(\"My client was locked in a store overnight, and wants to sue for negligence. This was in Alberta, Calgary actually. What part of the law should I look to\")\n",
    "response_eval = testmodel.generate(\"Do an initial analysis on the case for me. what sections of the law are relevant?\")\n",
    "\n",
    "print(response_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d26d54-dfcf-43ea-91e4-9515539d6cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
